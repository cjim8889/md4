{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b41e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/md4/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [CpuDevice(id=0)]\n",
      "JAX default backend: cpu\n",
      "Number of devices: 1\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Configure JAX to use CPU for easier debugging\n",
    "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "import functools\n",
    "from typing import Dict, Any\n",
    "\n",
    "import flax.linen as nn\n",
    "from ml_collections import config_dict\n",
    "from clu import parameter_overview\n",
    "from etils import epath\n",
    "\n",
    "# Add the md4 module to the path\n",
    "sys.path.append('/mnt/workspace/md4')\n",
    "\n",
    "from md4.configs.md4 import molecular_finetune, molecular\n",
    "from md4.models import utils as model_utils\n",
    "from md4 import train\n",
    "from md4 import partial_load_utils\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"JAX default backend: {jax.default_backend()}\")\n",
    "print(f\"Number of devices: {len(jax.devices())}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2695da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CONFIGURATION COMPARISON\n",
      "============================================================\n",
      "Key differences between old and new configs:\n",
      "  warmup_steps: 2000 ‚Üí 1000\n",
      "  frozen: <MISSING> ‚Üí True\n",
      "  num_eval_steps: 1000 ‚Üí 100\n",
      "  eval_every_steps: 20000 ‚Üí 2000\n",
      "  checkpoint_every_steps: 20000 ‚Üí 2000\n",
      "  partial_load: <MISSING> ‚Üí True\n",
      "  checkpoint_keep_period: 200000 ‚Üí 6000\n",
      "  learning_rate: 0.0003 ‚Üí 1e-05\n",
      "  learning_rate_schedule: cosine ‚Üí constant\n",
      "  frozen_paths: <MISSING> ‚Üí []\n",
      "  old_config: <MISSING> ‚Üí md4/configs/md4/molecular.py\n",
      "  num_train_steps: 1500000 ‚Üí 100000\n",
      "  dataset: pubchem_large ‚Üí msg_finetune\n",
      "  adapter_init_paths: <MISSING> ‚Üí ['fp_adapter']\n",
      "  unfrozen_paths: <MISSING> ‚Üí ['fp_adapter']\n",
      "  weight_decay: 1e-06 ‚Üí 0.0\n",
      "  fingerprint_adapter: <MISSING> ‚Üí True\n",
      "  raw_fingerprint_dim: <MISSING> ‚Üí 4096\n",
      "\n",
      "OLD CONFIG (molecular.py):\n",
      "  Model type: md4\n",
      "  Dataset: pubchem_large\n",
      "  Vocab size: 1024\n",
      "  Feature dim: 64\n",
      "  Fingerprint dim: 2048\n",
      "  Frozen mode: False\n",
      "\n",
      "NEW CONFIG (molecular_finetune.py):\n",
      "  Model type: md4\n",
      "  Dataset: msg_finetune\n",
      "  Vocab size: 1024\n",
      "  Feature dim: 64\n",
      "  Fingerprint dim: 2048\n",
      "  Frozen mode: True\n",
      "  Partial load: True\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load both configurations for comparison\n",
    "new_config = molecular_finetune.get_config()\n",
    "old_config = molecular.get_config()\n",
    "\n",
    "print(\"üîç CONFIGURATION COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def compare_configs(old_cfg, new_cfg, prefix=\"\"):\n",
    "    \"\"\"Compare two configurations and highlight differences.\"\"\"\n",
    "    differences = []\n",
    "    \n",
    "    for key in set(list(old_cfg.keys()) + list(new_cfg.keys())):\n",
    "        old_val = getattr(old_cfg, key, \"<MISSING>\")\n",
    "        new_val = getattr(new_cfg, key, \"<MISSING>\")\n",
    "        \n",
    "        if old_val != new_val:\n",
    "            differences.append((key, old_val, new_val))\n",
    "    \n",
    "    return differences\n",
    "\n",
    "differences = compare_configs(old_config, new_config)\n",
    "\n",
    "print(\"Key differences between old and new configs:\")\n",
    "for key, old_val, new_val in differences:\n",
    "    print(f\"  {key}: {old_val} ‚Üí {new_val}\")\n",
    "\n",
    "print(f\"\\nOLD CONFIG (molecular.py):\")\n",
    "print(f\"  Model type: {old_config.model_type}\")\n",
    "print(f\"  Dataset: {old_config.dataset}\")\n",
    "print(f\"  Vocab size: {old_config.vocab_size}\")\n",
    "print(f\"  Feature dim: {old_config.feature_dim}\")\n",
    "print(f\"  Fingerprint dim: {old_config.fingerprint_dim}\")\n",
    "print(f\"  Frozen mode: {old_config.get('frozen', False)}\")\n",
    "\n",
    "print(f\"\\nNEW CONFIG (molecular_finetune.py):\")\n",
    "print(f\"  Model type: {new_config.model_type}\")\n",
    "print(f\"  Dataset: {new_config.dataset}\")\n",
    "print(f\"  Vocab size: {new_config.vocab_size}\")\n",
    "print(f\"  Feature dim: {new_config.feature_dim}\")\n",
    "print(f\"  Fingerprint dim: {new_config.fingerprint_dim}\")\n",
    "print(f\"  Frozen mode: {new_config.get('frozen', False)}\")\n",
    "print(f\"  Partial load: {new_config.get('partial_load', False)}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81346e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  MODEL CREATION\n",
      "============================================================\n",
      "Old model: <class 'md4.models.diffusion.md4.MD4'>\n",
      "New model: <class 'md4.models.diffusion.md4.MD4'>\n",
      "Data shape: (128,)\n",
      "Per device batch size: 4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create models for both configurations\n",
    "print(\"üèóÔ∏è  MODEL CREATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "old_model = model_utils.get_model(old_config)\n",
    "new_model = model_utils.get_model(new_config)\n",
    "\n",
    "print(f\"Old model: {type(old_model)}\")\n",
    "print(f\"New model: {type(new_model)}\")\n",
    "\n",
    "# Set up common parameters\n",
    "per_device_batch_size = 4  # Small batch for testing\n",
    "data_shape = (new_config.max_length,)\n",
    "num_train_steps = 1000000\n",
    "\n",
    "schedule_fn = functools.partial(\n",
    "    train.get_learning_rate,\n",
    "    base_learning_rate=new_config.learning_rate,\n",
    "    num_steps=num_train_steps,\n",
    "    warmup_steps=new_config.warmup_steps,\n",
    "    schedule_type=new_config.learning_rate_schedule,\n",
    ")\n",
    "\n",
    "print(f\"Data shape: {data_shape}\")\n",
    "print(f\"Per device batch size: {per_device_batch_size}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbda82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New FROZEN train state created (step: 0)\n"
     ]
    }
   ],
   "source": [
    "new_rng = jax.random.PRNGKey(42)  # Same seed for reproducibility\n",
    "import md4.state_utils as state_utils\n",
    "new_model, new_optimizer, new_train_state, new_metrics_class = state_utils.create_train_state(\n",
    "    new_config,\n",
    "    new_rng,\n",
    "    input_shape=(per_device_batch_size,) + data_shape,\n",
    "    schedule_fn=schedule_fn,\n",
    ")\n",
    "print(f\"‚úÖ New FROZEN train state created (step: {new_train_state.step})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9812b039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cond_dense_0': {'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       "  'kernel': Array([[-2.0289680e-02,  2.5764512e-02, -5.0052800e-03, ...,\n",
       "           3.9162129e-02,  4.2294681e-02,  2.7065177e-02],\n",
       "         [ 2.0283964e-05,  1.2533314e-02,  4.0390089e-02, ...,\n",
       "           8.4358966e-03,  1.7612189e-02, -2.7960740e-02],\n",
       "         [ 2.8920980e-02, -3.3317164e-02,  1.8416533e-02, ...,\n",
       "          -5.2914713e-03,  4.3843381e-02, -7.5638820e-03],\n",
       "         ...,\n",
       "         [-3.1251512e-02, -1.4581830e-02,  1.9599354e-02, ...,\n",
       "          -2.8813062e-02, -1.7215077e-02, -3.7434134e-03],\n",
       "         [-7.7669602e-03, -8.6089112e-03, -2.3589877e-02, ...,\n",
       "          -1.2109401e-02,  6.1565200e-03,  3.5236843e-03],\n",
       "         [ 2.2222603e-02,  3.1736728e-02, -3.0510605e-03, ...,\n",
       "           4.2397384e-02, -1.5349303e-02, -3.1204224e-02]], dtype=float32)},\n",
       " 'cond_dense_1': {'bias': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  'kernel': Array([[-0.00097311, -0.02716308, -0.01276579, ..., -0.04710022,\n",
       "          -0.01319149,  0.0337001 ],\n",
       "         [ 0.03506861,  0.01657677,  0.01373899, ..., -0.01991819,\n",
       "          -0.01229997, -0.01744118],\n",
       "         [ 0.01767674,  0.05545741, -0.00334418, ..., -0.02945724,\n",
       "           0.01067748, -0.06129003],\n",
       "         ...,\n",
       "         [-0.03222366, -0.02251931,  0.04172127, ..., -0.01403953,\n",
       "           0.00507378,  0.03428217],\n",
       "         [-0.01478422,  0.01594622,  0.02190441, ...,  0.01459935,\n",
       "          -0.00673784,  0.01215281],\n",
       "         [-0.05819098, -0.00283923,  0.04325904, ...,  0.02952334,\n",
       "           0.02111718, -0.02322183]], dtype=float32)},\n",
       " 'cond_dense_2': {'bias': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  'kernel': Array([[-1.18947871e-01, -6.07047640e-02,  3.87718156e-02, ...,\n",
       "          -1.18289761e-01, -9.16299447e-02, -6.07887171e-02],\n",
       "         [-1.49742201e-01, -5.35368593e-03, -2.72189640e-02, ...,\n",
       "          -3.55647840e-02,  1.25941057e-02,  1.65432811e-01],\n",
       "         [ 1.12425700e-01,  5.95174655e-02,  1.39687822e-04, ...,\n",
       "           3.52791278e-03, -1.16086513e-01,  4.53632809e-02],\n",
       "         ...,\n",
       "         [-2.34594233e-02, -4.11541052e-02, -1.04032762e-01, ...,\n",
       "          -7.58302510e-02,  1.22327618e-01,  1.11803405e-01],\n",
       "         [-1.43188193e-01,  3.34252827e-02, -1.07360423e-01, ...,\n",
       "           6.26140460e-02, -1.71313941e-01,  7.94883594e-02],\n",
       "         [-1.47612885e-01, -2.85352264e-02,  5.03982231e-02, ...,\n",
       "          -2.62824856e-02,  3.02665345e-02, -5.12490310e-02]],      dtype=float32)},\n",
       " 'cond_dense_out': {'bias': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  'kernel': Array([[-0.00497199,  0.01162473,  0.0378929 , ...,  0.02970135,\n",
       "           0.0502169 , -0.0430864 ],\n",
       "         [-0.02686521, -0.07327241, -0.08172625, ...,  0.05563137,\n",
       "           0.11522964,  0.04134545],\n",
       "         [-0.11248286,  0.11783749, -0.09805931, ..., -0.13748525,\n",
       "           0.00511515,  0.24796568],\n",
       "         ...,\n",
       "         [-0.01304331, -0.23729436,  0.05688101, ...,  0.07039552,\n",
       "          -0.13768682,  0.03211346],\n",
       "         [-0.19665772, -0.01299532, -0.13150977, ...,  0.134104  ,\n",
       "           0.1506094 ,  0.05355401],\n",
       "         [-0.11758084,  0.02874817, -0.04497546, ...,  0.1002373 ,\n",
       "          -0.03306565, -0.04482545]], dtype=float32)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_state.params[\"cond_embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1725c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint directory: /mnt/workspace/md4/finetune_frozen_expt/checkpoints\n",
      "Latest new checkpoint step: 20000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "User-provided restore item and on-disk value metadata tree structures do not match: {'params': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)}, rhs=None)}}, 'ema_params': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)}, rhs=None)}}, 'opt_state': [None, {'inner_states': {'train': {'inner_state': [{'mu': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}, rhs=None)}}, 'nu': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}, rhs=None)}}}, None, None]}}}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load the new checkpoint\u001b[39;00m\n\u001b[32m      8\u001b[39m new_checkpointed_state = {\u001b[33m\"\u001b[39m\u001b[33mtrain_state\u001b[39m\u001b[33m\"\u001b[39m: copy.deepcopy(new_train_state)}\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m new_checkpointed_state = \u001b[43mnew_checkpoint_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_checkpoint_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlatest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_checkpointed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m new_checkpointed_state_2 = {\u001b[33m\"\u001b[39m\u001b[33mtrain_state\u001b[39m\u001b[33m\"\u001b[39m: copy.deepcopy(new_train_state)}\n\u001b[32m     15\u001b[39m new_checkpointed_state_2 = new_checkpoint_manager.restore(\n\u001b[32m     16\u001b[39m     \u001b[32m86000\u001b[39m, \n\u001b[32m     17\u001b[39m     items=new_checkpointed_state_2,\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/md4/.venv/lib/python3.13/site-packages/orbax/checkpoint/checkpoint_manager.py:1647\u001b[39m, in \u001b[36mCheckpointManager.restore\u001b[39m\u001b[34m(self, step, items, restore_kwargs, directory, args)\u001b[39m\n\u001b[32m   1645\u001b[39m restore_directory = \u001b[38;5;28mself\u001b[39m._get_read_step_directory(step, directory)\n\u001b[32m   1646\u001b[39m step_stats.checkpointer_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1647\u001b[39m restored = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_checkpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestore_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1648\u001b[39m step_stats.checkpointer_duration_secs = (\n\u001b[32m   1649\u001b[39m     time.time() - step_stats.checkpointer_start_time\n\u001b[32m   1650\u001b[39m )\n\u001b[32m   1652\u001b[39m step_stats.checkpoint_manager_duration_secs = (\n\u001b[32m   1653\u001b[39m     time.time() - step_stats.checkpoint_manager_start_time\n\u001b[32m   1654\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/md4/.venv/lib/python3.13/site-packages/orbax/checkpoint/_src/checkpointers/checkpointer.py:304\u001b[39m, in \u001b[36mCheckpointer.restore\u001b[39m\u001b[34m(self, directory, *args, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m logging.info(\u001b[33m'\u001b[39m\u001b[33mRestoring checkpoint from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, directory)\n\u001b[32m    303\u001b[39m ckpt_args = construct_checkpoint_args(\u001b[38;5;28mself\u001b[39m._handler, \u001b[38;5;28;01mFalse\u001b[39;00m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m restored = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_restore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m multihost.sync_global_processes(\n\u001b[32m    306\u001b[39m     multihost.unique_barrier_key(\n\u001b[32m    307\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCheckpointer:restore\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m     processes=\u001b[38;5;28mself\u001b[39m._active_processes,\n\u001b[32m    311\u001b[39m )\n\u001b[32m    312\u001b[39m restore_duration_secs = time.time() - restore_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/md4/.venv/lib/python3.13/site-packages/orbax/checkpoint/_src/checkpointers/checkpointer.py:323\u001b[39m, in \u001b[36mCheckpointer._restore\u001b[39m\u001b[34m(self, directory, args)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_restore\u001b[39m(\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m, directory: epath.PathLike, args: checkpoint_args.CheckpointArgs\n\u001b[32m    322\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/md4/.venv/lib/python3.13/site-packages/orbax/checkpoint/_src/handlers/composite_checkpoint_handler.py:859\u001b[39m, in \u001b[36mCompositeCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, args)\u001b[39m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    855\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mItem \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m was not found in the checkpoint. Available\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    856\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m items: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexisting_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    857\u001b[39m     )\n\u001b[32m    858\u001b[39m   handler = \u001b[38;5;28mself\u001b[39m._get_or_set_handler(item_name, arg)\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m   restored[item_name] = \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_item_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43marg\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompositeResults(**restored)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/md4/.venv/lib/python3.13/site-packages/orbax/checkpoint/_src/handlers/pytree_checkpoint_handler.py:816\u001b[39m, in \u001b[36mPyTreeCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, item, restore_args, transforms, transforms_default_to_original, legacy_transform_fn, args)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    806\u001b[39m     (directory / PYTREE_METADATA_FILE).exists()\n\u001b[32m    807\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m can_ignore_aggregate_file\n\u001b[32m    808\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m transforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    809\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m legacy_transform_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    810\u001b[39m ):\n\u001b[32m    811\u001b[39m   args = BasePyTreeRestoreArgs(\n\u001b[32m    812\u001b[39m       item,\n\u001b[32m    813\u001b[39m       restore_args=restore_args,\n\u001b[32m    814\u001b[39m       partial_restore=args.partial_restore,\n\u001b[32m    815\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handler_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m logging.vlog(\u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdirectory=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, restore_args=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, directory, restore_args)\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m directory.exists():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/md4/.venv/lib/python3.13/site-packages/orbax/checkpoint/_src/handlers/base_pytree_checkpoint_handler.py:792\u001b[39m, in \u001b[36mBasePyTreeCheckpointHandler.restore\u001b[39m\u001b[34m(self, directory, args)\u001b[39m\n\u001b[32m    785\u001b[39m   diff = tree_structure_utils.tree_difference(\n\u001b[32m    786\u001b[39m       serialized_item,\n\u001b[32m    787\u001b[39m       value_metadata_tree,\n\u001b[32m    788\u001b[39m       is_leaf=tree_utils.is_empty_or_leaf,\n\u001b[32m    789\u001b[39m       leaves_equal=\u001b[38;5;28;01mlambda\u001b[39;00m a, b: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    790\u001b[39m   )\n\u001b[32m    791\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    793\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mUser-provided restore item and on-disk value metadata tree\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    794\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m structures do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    795\u001b[39m     )\n\u001b[32m    796\u001b[39m   value_metadata_tree = jax.tree.map(\n\u001b[32m    797\u001b[39m       \u001b[38;5;28;01mlambda\u001b[39;00m v, i: PLACEHOLDER \u001b[38;5;28;01mif\u001b[39;00m type_handlers.is_placeholder(i) \u001b[38;5;28;01melse\u001b[39;00m v,\n\u001b[32m    798\u001b[39m       value_metadata_tree,\n\u001b[32m    799\u001b[39m       serialized_item,\n\u001b[32m    800\u001b[39m   )\n\u001b[32m    801\u001b[39m restore_args = _fill_missing_save_or_restore_args(\n\u001b[32m    802\u001b[39m     item, restore_args, mode=\u001b[33m'\u001b[39m\u001b[33mrestore\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    803\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: User-provided restore item and on-disk value metadata tree structures do not match: {'params': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)}, rhs=None)}}, 'ema_params': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)}, rhs=None)}}, 'opt_state': [None, {'inner_states': {'train': {'inner_state': [{'mu': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}, rhs=None)}}, 'nu': {'fp_adapter': {'fingerprint_adapter_out': Diff(lhs={'bias': Array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'kernel': Array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}, rhs=None)}}}, None, None]}}}]}"
     ]
    }
   ],
   "source": [
    "new_workdir = \"/mnt/workspace/md4/finetune_frozen_expt\"\n",
    "new_checkpoint_manager = checkpoint_utils._get_checkpoint_manager(new_config, new_workdir, create=False)\n",
    "\n",
    "print(f\"New checkpoint directory: {epath.Path(new_workdir) / 'checkpoints'}\")\n",
    "print(f\"Latest new checkpoint step: {new_checkpoint_manager.latest_step()}\")\n",
    "\n",
    "# Load the new checkpoint\n",
    "new_checkpointed_state = {\"train_state\": copy.deepcopy(new_train_state)}\n",
    "new_checkpointed_state = new_checkpoint_manager.restore(\n",
    "    new_checkpoint_manager.latest_step(), \n",
    "    items=new_checkpointed_state,\n",
    ")\n",
    "\n",
    "new_checkpointed_state_2 = {\"train_state\": copy.deepcopy(new_train_state)}\n",
    "new_checkpointed_state_2 = new_checkpoint_manager.restore(\n",
    "    86000, \n",
    "    items=new_checkpointed_state_2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23ff5fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÇ TRAIN STATE CREATION\n",
      "============================================================\n",
      "‚úÖ Old train state created (step: 0)\n",
      "   Parameters keys: ['classifier', 'cond_embeddings']\n",
      "‚úÖ New FROZEN train state created (step: 0)\n",
      "   Parameters keys: ['classifier', 'cond_embeddings', 'fp_adapter']\n",
      "\n",
      "Parameter structure comparison:\n",
      "Old model parameters: ['classifier', 'cond_embeddings']\n",
      "New model parameters: ['classifier', 'cond_embeddings', 'fp_adapter']\n",
      "‚ú® Parameters only in new model: {'fp_adapter'}\n",
      "‚úÖ Common parameters: {'cond_embeddings', 'classifier'}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create train states for both models\n",
    "print(\"üöÇ TRAIN STATE CREATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create old train state (regular)\n",
    "old_rng = jax.random.PRNGKey(42)\n",
    "old_model, old_optimizer, old_train_state, old_metrics_class = train.create_train_state(\n",
    "    old_config,\n",
    "    old_rng,\n",
    "    input_shape=(per_device_batch_size,) + data_shape,\n",
    "    schedule_fn=schedule_fn,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Old train state created (step: {old_train_state.step})\")\n",
    "print(f\"   Parameters keys: {list(old_train_state.params.keys())}\")\n",
    "\n",
    "# Create new train state (frozen)\n",
    "if new_config.get('frozen', False):\n",
    "    new_model, new_optimizer, new_train_state, new_metrics_class = train.create_frozen_train_state(\n",
    "        new_config,\n",
    "        new_rng,\n",
    "        input_shape=(per_device_batch_size,) + data_shape,\n",
    "        schedule_fn=schedule_fn,\n",
    "    )\n",
    "    print(f\"‚úÖ New FROZEN train state created (step: {new_train_state.step})\")\n",
    "else:\n",
    "    new_model, new_optimizer, new_train_state, new_metrics_class = train.create_train_state(\n",
    "        new_config,\n",
    "        new_rng,\n",
    "        input_shape=(per_device_batch_size,) + data_shape,\n",
    "        schedule_fn=schedule_fn,\n",
    "    )\n",
    "    print(f\"‚úÖ New regular train state created (step: {new_train_state.step})\")\n",
    "\n",
    "print(f\"   Parameters keys: {list(new_train_state.params.keys())}\")\n",
    "\n",
    "# Compare parameter structures\n",
    "def get_param_structure(params, prefix=\"\"):\n",
    "    \"\"\"Get a nested dictionary showing parameter shapes.\"\"\"\n",
    "    structure = {}\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, dict):\n",
    "            structure[key] = get_param_structure(value, f\"{prefix}.{key}\")\n",
    "        else:\n",
    "            structure[key] = value.shape\n",
    "    return structure\n",
    "\n",
    "old_structure = get_param_structure(old_train_state.params)\n",
    "new_structure = get_param_structure(new_train_state.params)\n",
    "\n",
    "print(f\"\\nParameter structure comparison:\")\n",
    "print(f\"Old model parameters: {list(old_structure.keys())}\")\n",
    "print(f\"New model parameters: {list(new_structure.keys())}\")\n",
    "\n",
    "# Find differences\n",
    "old_only = set(old_structure.keys()) - set(new_structure.keys())\n",
    "new_only = set(new_structure.keys()) - set(old_structure.keys())\n",
    "common = set(old_structure.keys()) & set(new_structure.keys())\n",
    "\n",
    "if old_only:\n",
    "    print(f\"‚ùå Parameters only in old model: {old_only}\")\n",
    "if new_only:\n",
    "    print(f\"‚ú® Parameters only in new model: {new_only}\")\n",
    "print(f\"‚úÖ Common parameters: {common}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c84261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    }
   ],
   "source": [
    "old_workdir = \"/mnt/workspace/md4/large_expt\"\n",
    "old_checkpoint_manager = checkpoint_utils._get_checkpoint_manager(old_config, old_workdir, create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87acac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_loaded_checkpoint, _ = train.partial_load_utils.partial_load_checkpoint(\n",
    "    old_config,\n",
    "    new_train_state,\n",
    "    train_iter=None,\n",
    "    checkpoint_manager=old_checkpoint_manager,\n",
    "    create_train_state_fn=train.create_train_state,\n",
    "    schedule_fn=schedule_fn,\n",
    "    per_device_batch_size= per_device_batch_size,\n",
    "    data_shape=data_shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fdea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a7cdfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10222556,  0.05280137,  0.01212622,  0.12334919, -0.09347872,\n",
       "       -0.0856513 ,  0.08631224, -0.01410997,  0.16532548,  0.10793076,\n",
       "        0.00095248, -0.15173772,  0.11472066, -0.03458977, -0.08238201,\n",
       "       -0.04790057, -0.0243195 , -0.14598721, -0.25267345, -0.00888992,\n",
       "        0.07931393, -0.12354071, -0.14782493, -0.00068826, -0.12568152,\n",
       "       -0.16664398, -0.09426703,  0.04617818, -0.12923817,  0.00388334,\n",
       "       -0.18511422,  0.0141763 ,  0.19037528, -0.20642547,  0.11950786,\n",
       "       -0.06452266,  0.18228224, -0.04121022,  0.05384567,  0.04185708,\n",
       "        0.02210524,  0.07651379, -0.12801877, -0.06195638, -0.1300139 ,\n",
       "       -0.060221  ,  0.24796437,  0.15395756, -0.1924481 , -0.00986998,\n",
       "        0.09546501,  0.01254566,  0.00191896, -0.09120514, -0.06756873,\n",
       "        0.03463075,  0.02213649,  0.00371821, -0.02300274,  0.09934283,\n",
       "       -0.00430454,  0.06706794, -0.04506921,  0.22055061], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partially_loaded_checkpoint.params[\"cond_embeddings\"][\"cond_dense_out\"][\"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4c6c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_checkpointed_state = {\"train_state\": old_train_state}\n",
    "old_checkpointed_state = old_checkpoint_manager.restore(\n",
    "    old_checkpoint_manager.latest_step(), \n",
    "    items=old_checkpointed_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff03f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['classifier', 'cond_embeddings', 'fp_adapter'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partially_loaded_checkpoint.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cbbb166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ LOADING OLD CHECKPOINT\n",
      "============================================================\n",
      "Old checkpoint directory: /mnt/workspace/md4/large_expt/checkpoints\n",
      "Latest old checkpoint step: 1440000\n",
      "‚úÖ Old checkpoint loaded successfully\n",
      "   Loaded step: 1440000\n",
      "   Parameter keys: ['classifier', 'cond_embeddings']\n",
      "   Total parameters: +---------------------------------------------------------------------+--------------+---------+-----------+-----------+--------+\n",
      "| Name                                                                | Shape        | Dtype   | Size      | Mean      | Std    |\n",
      "+---------------------------------------------------------------------+--------------+---------+-----------+-----------+--------+\n",
      "| classifier/CondEmbedding_0/Dense_0/bias                             | (64,)        | float32 | 64        | -0.136    | 0.209  |\n",
      "| classifier/CondEmbedding_0/Dense_0/kernel                           | (256, 64)    | float32 | 16,384    | 0.0184    | 0.0984 |\n",
      "| classifier/CondEmbedding_0/dense0/bias                              | (256,)       | float32 | 256       | -0.0635   | 0.103  |\n",
      "| classifier/CondEmbedding_0/dense0/kernel                            | (128, 256)   | float32 | 32,768    | -0.0101   | 0.0847 |\n",
      "| classifier/Embed_0/embedding                                        | (1025, 64)   | float32 | 65,600    | 0.00137   | 0.215  |\n",
      "| classifier/Transformer_0/Dense_0/bias                               | (1024,)      | float32 | 1,024     | 0.00538   | 0.336  |\n",
      "| classifier/Transformer_0/Dense_0/kernel                             | (64, 1024)   | float32 | 65,536    | -0.00119  | 0.231  |\n",
      "| classifier/Transformer_0/Dense_1/bias                               | (2048,)      | float32 | 2,048     | -0.0638   | 0.18   |\n",
      "| classifier/Transformer_0/Dense_1/kernel                             | (64, 2048)   | float32 | 131,072   | 0.0169    | 0.157  |\n",
      "| classifier/Transformer_0/Dense_2/kernel                             | (1024, 1024) | float32 | 1,048,576 | 0.00284   | 0.194  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.162    | 0.246  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.00717   | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | 3.22e-05  | 0.0842 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000144  | 0.109  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | 8.21e-05  | 0.0822 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 6.42e-06  | 0.0525 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00288  | 0.176  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 0.000238  | 0.17   |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | 3.12e-05  | 0.157  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0967   | 0.172  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.000907  | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000114 | 0.152  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000172 | 0.151  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000509  | 0.148  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000341 | 0.132  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -6.29e-05 | 0.166  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 7.57e-05  | 0.164  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | 4.44e-05  | 0.158  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/Dense_0/bias           | (6144,)      | float32 | 6,144     | 0.0165    | 0.177  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/Dense_0/kernel         | (64, 6144)   | float32 | 393,216   | 0.00111   | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wk/kernel    | (1024, 1024) | float32 | 1,048,576 | -0.000112 | 0.164  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wo/kernel    | (1024, 1024) | float32 | 1,048,576 | -0.00033  | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wq/kernel    | (1024, 1024) | float32 | 1,048,576 | 0.000466  | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wv/kernel    | (1024, 1024) | float32 | 1,048,576 | -0.000402 | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w1/kernel | (1024, 2816) | float32 | 2,883,584 | -0.000516 | 0.19   |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w2/kernel | (2816, 1024) | float32 | 2,883,584 | -4.18e-05 | 0.199  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w3/kernel | (1024, 2816) | float32 | 2,883,584 | -9.98e-05 | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_11/Dense_0/bias           | (6144,)      | float32 | 6,144     | -0.0438   | 0.577  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/Dense_0/kernel         | (64, 6144)   | float32 | 393,216   | 0.00084   | 0.357  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wk/kernel    | (1024, 1024) | float32 | 1,048,576 | 0.000663  | 0.129  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wo/kernel    | (1024, 1024) | float32 | 1,048,576 | 0.000289  | 0.256  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wq/kernel    | (1024, 1024) | float32 | 1,048,576 | -0.000195 | 0.126  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wv/kernel    | (1024, 1024) | float32 | 1,048,576 | -0.000533 | 0.244  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w1/kernel | (1024, 2816) | float32 | 2,883,584 | 0.000939  | 0.192  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w2/kernel | (2816, 1024) | float32 | 2,883,584 | 0.000155  | 0.204  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w3/kernel | (1024, 2816) | float32 | 2,883,584 | 3.94e-05  | 0.202  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0404   | 0.131  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | -0.00205  | 0.157  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000141  | 0.156  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000107  | 0.159  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000293  | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 8.24e-05  | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00136  | 0.179  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 7.79e-05  | 0.186  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | 0.000173  | 0.185  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0415   | 0.129  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | -0.00142  | 0.158  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000177 | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000231  | 0.172  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000369 | 0.153  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000541  | 0.171  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00167  | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 3.26e-05  | 0.187  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | 2.33e-05  | 0.188  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0356   | 0.133  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | -0.000788 | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000147  | 0.156  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.00043   | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000394 | 0.154  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000157 | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00101  | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 0.000214  | 0.193  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | 7.84e-05  | 0.193  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0319   | 0.135  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.000305  | 0.173  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.00033   | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 1.67e-05  | 0.186  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | -8.31e-05 | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000387  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00136  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 0.000203  | 0.196  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.000104 | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_6/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.036    | 0.144  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.000147  | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | -6.41e-05 | 0.152  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000168  | 0.188  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000451  | 0.154  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000149  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00165  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | -7.65e-05 | 0.194  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | -1.86e-05 | 0.198  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0435   | 0.177  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.000633  | 0.185  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.00014   | 0.149  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000112  | 0.206  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000192  | 0.15   |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000311  | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00244  | 0.187  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | -3.2e-05  | 0.195  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | 7.25e-05  | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_8/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.00678  | 0.133  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.000167  | 0.16   |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | 8.61e-05  | 0.164  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 8e-05     | 0.192  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | -0.000339 | 0.166  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000249  | 0.191  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.00131  | 0.187  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | -3.18e-05 | 0.194  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.000101 | 0.198  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/Dense_0/bias            | (6144,)      | float32 | 6,144     | -0.0464   | 0.262  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/Dense_0/kernel          | (64, 6144)   | float32 | 393,216   | 0.00107   | 0.212  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576 | -3.2e-05  | 0.143  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.000136  | 0.223  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576 | 0.00014   | 0.144  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576 | -9.86e-05 | 0.216  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584 | -0.000743 | 0.189  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584 | 0.000118  | 0.196  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584 | -2.92e-05 | 0.2    |\n",
      "| cond_embeddings/cond_dense_0/bias                                   | (1024,)      | float32 | 1,024     | -0.381    | 0.31   |\n",
      "| cond_embeddings/cond_dense_0/kernel                                 | (2048, 1024) | float32 | 2,097,152 | -0.00587  | 0.132  |\n",
      "| cond_embeddings/cond_dense_1/bias                                   | (128,)       | float32 | 128       | -0.0232   | 0.189  |\n",
      "| cond_embeddings/cond_dense_1/kernel                                 | (1024, 128)  | float32 | 131,072   | -0.000151 | 0.0857 |\n",
      "| cond_embeddings/cond_dense_2/bias                                   | (64,)        | float32 | 64        | 0.0156    | 0.119  |\n",
      "| cond_embeddings/cond_dense_2/kernel                                 | (128, 64)    | float32 | 8,192     | -0.0106   | 0.14   |\n",
      "| cond_embeddings/cond_dense_out/bias                                 | (64,)        | float32 | 64        | -0.00759  | 0.109  |\n",
      "| cond_embeddings/cond_dense_out/kernel                               | (64, 64)     | float32 | 4,096     | 0.00218   | 0.127  |\n",
      "+---------------------------------------------------------------------+--------------+---------+-----------+-----------+--------+\n",
      "Total: 162,538,112 -- 650,152,448 bytes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load old checkpoint\n",
    "print(\"üìÇ LOADING OLD CHECKPOINT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "old_workdir = \"/mnt/workspace/md4/large_expt\"\n",
    "old_checkpoint_manager = checkpoint_utils._get_checkpoint_manager(old_config, old_workdir, create=False)\n",
    "\n",
    "print(f\"Old checkpoint directory: {epath.Path(old_workdir) / 'checkpoints'}\")\n",
    "print(f\"Latest old checkpoint step: {old_checkpoint_manager.latest_step()}\")\n",
    "\n",
    "if old_checkpoint_manager.latest_step() is not None:\n",
    "    # Load the old checkpoint\n",
    "    old_checkpointed_state = {\"train_state\": old_train_state}\n",
    "    old_checkpointed_state = old_checkpoint_manager.restore(\n",
    "        old_checkpoint_manager.latest_step(), \n",
    "        items=old_checkpointed_state,\n",
    "    )\n",
    "    \n",
    "    loaded_old_train_state = old_checkpointed_state[\"train_state\"]\n",
    "    \n",
    "    print(f\"‚úÖ Old checkpoint loaded successfully\")\n",
    "    print(f\"   Loaded step: {loaded_old_train_state.step}\")\n",
    "    print(f\"   Parameter keys: {list(loaded_old_train_state.params.keys())}\")\n",
    "    \n",
    "    # Get parameter overview\n",
    "    old_overview = parameter_overview.get_parameter_overview(loaded_old_train_state.params)\n",
    "    print(f\"   Total parameters: {old_overview}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No old checkpoint found!\")\n",
    "    loaded_old_train_state = None\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd61964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ LOADING NEW CHECKPOINT\n",
      "============================================================\n",
      "New checkpoint directory: /mnt/workspace/md4/finetune_frozen_expt/checkpoints\n",
      "Latest new checkpoint step: 10000\n",
      "‚úÖ New checkpoint loaded successfully\n",
      "   Loaded step: 10000\n",
      "   Parameter keys: ['classifier', 'cond_embeddings', 'fp_adapter']\n",
      "   Total parameters: +---------------------------------------------------------------------+--------------+---------+------------+-----------+--------+\n",
      "| Name                                                                | Shape        | Dtype   | Size       | Mean      | Std    |\n",
      "+---------------------------------------------------------------------+--------------+---------+------------+-----------+--------+\n",
      "| classifier/CondEmbedding_0/Dense_0/bias                             | (64,)        | float32 | 64         | -0.136    | 0.209  |\n",
      "| classifier/CondEmbedding_0/Dense_0/kernel                           | (256, 64)    | float32 | 16,384     | 0.0184    | 0.0984 |\n",
      "| classifier/CondEmbedding_0/dense0/bias                              | (256,)       | float32 | 256        | -0.0635   | 0.103  |\n",
      "| classifier/CondEmbedding_0/dense0/kernel                            | (128, 256)   | float32 | 32,768     | -0.0101   | 0.0847 |\n",
      "| classifier/Embed_0/embedding                                        | (1025, 64)   | float32 | 65,600     | 0.00137   | 0.215  |\n",
      "| classifier/Transformer_0/Dense_0/bias                               | (1024,)      | float32 | 1,024      | 0.00538   | 0.336  |\n",
      "| classifier/Transformer_0/Dense_0/kernel                             | (64, 1024)   | float32 | 65,536     | -0.00119  | 0.231  |\n",
      "| classifier/Transformer_0/Dense_1/bias                               | (2048,)      | float32 | 2,048      | -0.0638   | 0.18   |\n",
      "| classifier/Transformer_0/Dense_1/kernel                             | (64, 2048)   | float32 | 131,072    | 0.0169    | 0.157  |\n",
      "| classifier/Transformer_0/Dense_2/kernel                             | (1024, 1024) | float32 | 1,048,576  | 0.00284   | 0.194  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.162    | 0.246  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.00717   | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | 3.22e-05  | 0.0842 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000144  | 0.109  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | 8.21e-05  | 0.0822 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 6.42e-06  | 0.0525 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00288  | 0.176  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 0.000238  | 0.17   |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | 3.12e-05  | 0.157  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0967   | 0.172  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.000907  | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000114 | 0.152  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000172 | 0.151  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000509  | 0.148  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000341 | 0.132  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -6.29e-05 | 0.166  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 7.57e-05  | 0.164  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | 4.44e-05  | 0.158  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/Dense_0/bias           | (6144,)      | float32 | 6,144      | 0.0165    | 0.177  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/Dense_0/kernel         | (64, 6144)   | float32 | 393,216    | 0.00111   | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wk/kernel    | (1024, 1024) | float32 | 1,048,576  | -0.000112 | 0.164  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wo/kernel    | (1024, 1024) | float32 | 1,048,576  | -0.00033  | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wq/kernel    | (1024, 1024) | float32 | 1,048,576  | 0.000466  | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wv/kernel    | (1024, 1024) | float32 | 1,048,576  | -0.000402 | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w1/kernel | (1024, 2816) | float32 | 2,883,584  | -0.000516 | 0.19   |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w2/kernel | (2816, 1024) | float32 | 2,883,584  | -4.18e-05 | 0.199  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w3/kernel | (1024, 2816) | float32 | 2,883,584  | -9.98e-05 | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_11/Dense_0/bias           | (6144,)      | float32 | 6,144      | -0.0438   | 0.577  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/Dense_0/kernel         | (64, 6144)   | float32 | 393,216    | 0.00084   | 0.357  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wk/kernel    | (1024, 1024) | float32 | 1,048,576  | 0.000663  | 0.129  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wo/kernel    | (1024, 1024) | float32 | 1,048,576  | 0.000289  | 0.256  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wq/kernel    | (1024, 1024) | float32 | 1,048,576  | -0.000195 | 0.126  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wv/kernel    | (1024, 1024) | float32 | 1,048,576  | -0.000533 | 0.244  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w1/kernel | (1024, 2816) | float32 | 2,883,584  | 0.000939  | 0.192  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w2/kernel | (2816, 1024) | float32 | 2,883,584  | 0.000155  | 0.204  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w3/kernel | (1024, 2816) | float32 | 2,883,584  | 3.94e-05  | 0.202  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0404   | 0.131  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | -0.00205  | 0.157  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000141  | 0.156  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000107  | 0.159  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000293  | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 8.24e-05  | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00136  | 0.179  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 7.79e-05  | 0.186  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | 0.000173  | 0.185  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0415   | 0.129  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | -0.00142  | 0.158  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000177 | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000231  | 0.172  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000369 | 0.153  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000541  | 0.171  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00167  | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 3.26e-05  | 0.187  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | 2.33e-05  | 0.188  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0356   | 0.133  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | -0.000788 | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000147  | 0.156  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.00043   | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000394 | 0.154  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000157 | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00101  | 0.18   |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 0.000214  | 0.193  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | 7.84e-05  | 0.193  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0319   | 0.135  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.000305  | 0.173  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.00033   | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 1.67e-05  | 0.186  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | -8.31e-05 | 0.155  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000387  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00136  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 0.000203  | 0.196  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.000104 | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_6/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.036    | 0.144  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.000147  | 0.167  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | -6.41e-05 | 0.152  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000168  | 0.188  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000451  | 0.154  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000149  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00165  | 0.183  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | -7.65e-05 | 0.194  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | -1.86e-05 | 0.198  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0435   | 0.177  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.000633  | 0.185  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.00014   | 0.149  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000112  | 0.206  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000192  | 0.15   |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000311  | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00244  | 0.187  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | -3.2e-05  | 0.195  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | 7.25e-05  | 0.2    |\n",
      "| classifier/Transformer_0/TransformerBlock_8/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.00678  | 0.133  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.000167  | 0.16   |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | 8.61e-05  | 0.164  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 8e-05     | 0.192  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | -0.000339 | 0.166  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000249  | 0.191  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.00131  | 0.187  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | -3.18e-05 | 0.194  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.000101 | 0.198  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/Dense_0/bias            | (6144,)      | float32 | 6,144      | -0.0464   | 0.262  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/Dense_0/kernel          | (64, 6144)   | float32 | 393,216    | 0.00107   | 0.212  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wk/kernel     | (1024, 1024) | float32 | 1,048,576  | -3.2e-05  | 0.143  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wo/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.000136  | 0.223  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wq/kernel     | (1024, 1024) | float32 | 1,048,576  | 0.00014   | 0.144  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wv/kernel     | (1024, 1024) | float32 | 1,048,576  | -9.86e-05 | 0.216  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w1/kernel  | (1024, 2816) | float32 | 2,883,584  | -0.000743 | 0.189  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w2/kernel  | (2816, 1024) | float32 | 2,883,584  | 0.000118  | 0.196  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w3/kernel  | (1024, 2816) | float32 | 2,883,584  | -2.92e-05 | 0.2    |\n",
      "| cond_embeddings/cond_dense_0/bias                                   | (1024,)      | float32 | 1,024      | -0.385    | 0.303  |\n",
      "| cond_embeddings/cond_dense_0/kernel                                 | (2048, 1024) | float32 | 2,097,152  | -0.00587  | 0.132  |\n",
      "| cond_embeddings/cond_dense_1/bias                                   | (128,)       | float32 | 128        | -0.0232   | 0.189  |\n",
      "| cond_embeddings/cond_dense_1/kernel                                 | (1024, 128)  | float32 | 131,072    | -0.000151 | 0.0857 |\n",
      "| cond_embeddings/cond_dense_2/bias                                   | (64,)        | float32 | 64         | 0.0156    | 0.119  |\n",
      "| cond_embeddings/cond_dense_2/kernel                                 | (128, 64)    | float32 | 8,192      | -0.0106   | 0.14   |\n",
      "| cond_embeddings/cond_dense_out/bias                                 | (64,)        | float32 | 64         | -0.00759  | 0.109  |\n",
      "| cond_embeddings/cond_dense_out/kernel                               | (64, 64)     | float32 | 4,096      | 0.00218   | 0.127  |\n",
      "| fp_adapter/fingerprint_adapter_dense/bias                           | (4096,)      | float32 | 4,096      | 0.0       | 0.0    |\n",
      "| fp_adapter/fingerprint_adapter_dense/kernel                         | (4096, 4096) | float32 | 16,777,216 | 1.09e-06  | 0.0156 |\n",
      "| fp_adapter/fingerprint_adapter_out/bias                             | (4096,)      | float32 | 4,096      | 0.0       | 0.0    |\n",
      "| fp_adapter/fingerprint_adapter_out/kernel                           | (4096, 4096) | float32 | 16,777,216 | 5.87e-06  | 0.0156 |\n",
      "+---------------------------------------------------------------------+--------------+---------+------------+-----------+--------+\n",
      "Total: 196,100,736 -- 784,402,944 bytes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load new checkpoint (if it exists)\n",
    "print(\"üìÇ LOADING NEW CHECKPOINT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "new_workdir = \"/mnt/workspace/md4/finetune_frozen_expt\"\n",
    "new_checkpoint_manager = checkpoint_utils._get_checkpoint_manager(new_config, new_workdir, create=False)\n",
    "\n",
    "print(f\"New checkpoint directory: {epath.Path(new_workdir) / 'checkpoints'}\")\n",
    "print(f\"Latest new checkpoint step: {new_checkpoint_manager.latest_step()}\")\n",
    "\n",
    "loaded_new_train_state = None\n",
    "if new_checkpoint_manager.latest_step() is not None:\n",
    "    # Load the new checkpoint\n",
    "    new_checkpointed_state = {\"train_state\": new_train_state}\n",
    "    new_checkpointed_state = new_checkpoint_manager.restore(\n",
    "        new_checkpoint_manager.latest_step(), \n",
    "        items=new_checkpointed_state,\n",
    "    )\n",
    "    \n",
    "    loaded_new_train_state = new_checkpointed_state[\"train_state\"]\n",
    "    \n",
    "    print(f\"‚úÖ New checkpoint loaded successfully\")\n",
    "    print(f\"   Loaded step: {loaded_new_train_state.step}\")\n",
    "    print(f\"   Parameter keys: {list(loaded_new_train_state.params.keys())}\")\n",
    "    \n",
    "    # Get parameter overview\n",
    "    new_overview = parameter_overview.get_parameter_overview(loaded_new_train_state.params)\n",
    "    print(f\"   Total parameters: {new_overview}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No new checkpoint found (expected for fresh setup)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363494c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ SIMULATING PARTIAL LOADING\n",
      "============================================================\n",
      "Performing manual partial loading simulation...\n",
      "Loaded old parameters: ['classifier', 'cond_embeddings']\n",
      "‚úÖ Parameters copied from old model: ['classifier', 'cond_embeddings']\n",
      "‚ùå Parameters skipped (not in new model): []\n",
      "‚ú® Parameters kept as new (not in old model): ['fp_adapter']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Simulate the partial loading process\n",
    "print(\"üîÑ SIMULATING PARTIAL LOADING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if loaded_old_train_state is not None:\n",
    "    print(\"Performing manual partial loading simulation...\")\n",
    "    \n",
    "    # Get the loaded parameters from old checkpoint\n",
    "    loaded_params = loaded_old_train_state.params\n",
    "    loaded_ema_params = getattr(loaded_old_train_state, \"ema_params\", None)\n",
    "    \n",
    "    print(f\"Loaded old parameters: {list(loaded_params.keys())}\")\n",
    "    \n",
    "    # Create a fresh new train state (to simulate partial loading)\n",
    "    fresh_new_train_state = new_train_state\n",
    "    \n",
    "    # Copy compatible parameters manually (simulating partial_load_utils logic)\n",
    "    merged_params = dict(fresh_new_train_state.params)\n",
    "    merged_ema_params = (\n",
    "        dict(fresh_new_train_state.ema_params)\n",
    "        if hasattr(fresh_new_train_state, \"ema_params\") and fresh_new_train_state.ema_params is not None\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    params_copied = []\n",
    "    params_skipped = []\n",
    "    params_new = []\n",
    "    \n",
    "    # Copy parameters that exist in both models\n",
    "    for key in loaded_params:\n",
    "        if key in merged_params:\n",
    "            merged_params[key] = loaded_params[key]\n",
    "            params_copied.append(key)\n",
    "        else:\n",
    "            params_skipped.append(key)\n",
    "    \n",
    "    # Copy EMA parameters if they exist\n",
    "    if merged_ema_params is not None and loaded_ema_params is not None:\n",
    "        for key in loaded_ema_params:\n",
    "            if key in merged_ema_params:\n",
    "                merged_ema_params[key] = loaded_ema_params[key]\n",
    "    \n",
    "    # Find parameters that are new in the current model\n",
    "    for key in merged_params:\n",
    "        if key not in loaded_params:\n",
    "            params_new.append(key)\n",
    "    \n",
    "    # Create the merged train state\n",
    "    merged_train_state = fresh_new_train_state.replace(\n",
    "        params=merged_params,\n",
    "        ema_params=merged_ema_params,\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Parameters copied from old model: {params_copied}\")\n",
    "    print(f\"‚ùå Parameters skipped (not in new model): {params_skipped}\")\n",
    "    print(f\"‚ú® Parameters kept as new (not in old model): {params_new}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot simulate partial loading - no old checkpoint available\")\n",
    "    merged_train_state = None\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "019a9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DETAILED PARAMETER COMPARISON\n",
      "============================================================\n",
      "1Ô∏è‚É£ FRESH NEW MODEL (before partial loading)\n",
      "\n",
      "Fresh New Parameter Analysis:\n",
      "  classifier:\n",
      "  cond_embeddings:\n",
      "  fp_adapter:\n",
      "  Total parameters: 0\n",
      "\n",
      "2Ô∏è‚É£ LOADED OLD MODEL\n",
      "\n",
      "Loaded Old Parameter Analysis:\n",
      "  classifier:\n",
      "  cond_embeddings:\n",
      "  Total parameters: 0\n",
      "\n",
      "3Ô∏è‚É£ MERGED MODEL (after partial loading)\n",
      "\n",
      "Merged Parameter Analysis:\n",
      "  classifier:\n",
      "  cond_embeddings:\n",
      "  fp_adapter:\n",
      "  Total parameters: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Detailed parameter comparison\n",
    "print(\"üîç DETAILED PARAMETER COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def analyze_parameter_tree(params, name):\n",
    "    \"\"\"Analyze a parameter tree and return statistics.\"\"\"\n",
    "    print(f\"\\n{name} Parameter Analysis:\")\n",
    "    \n",
    "    def get_stats(arr):\n",
    "        return {\n",
    "            'shape': arr.shape,\n",
    "            'mean': float(jnp.mean(arr)),\n",
    "            'std': float(jnp.std(arr)),\n",
    "            'min': float(jnp.min(arr)),\n",
    "            'max': float(jnp.max(arr)),\n",
    "            'num_params': int(jnp.prod(jnp.array(arr.shape)))\n",
    "        }\n",
    "    \n",
    "    total_params = 0\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}:\")\n",
    "        if isinstance(value, dict):\n",
    "            for subkey, subvalue in value.items():\n",
    "                if hasattr(subvalue, 'shape'):  # It's an array\n",
    "                    stats = get_stats(subvalue)\n",
    "                    total_params += stats['num_params']\n",
    "                    print(f\"    {subkey}: {stats}\")\n",
    "        elif hasattr(value, 'shape'):  # It's an array\n",
    "            stats = get_stats(value)\n",
    "            total_params += stats['num_params']\n",
    "            print(f\"    {stats}\")\n",
    "    \n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    return total_params\n",
    "\n",
    "if loaded_old_train_state is not None:\n",
    "    # Analyze original fresh new state\n",
    "    print(\"1Ô∏è‚É£ FRESH NEW MODEL (before partial loading)\")\n",
    "    fresh_total = analyze_parameter_tree(new_train_state.params, \"Fresh New\")\n",
    "    \n",
    "    # Analyze loaded old state\n",
    "    print(\"\\n2Ô∏è‚É£ LOADED OLD MODEL\")\n",
    "    old_total = analyze_parameter_tree(loaded_old_train_state.params, \"Loaded Old\")\n",
    "    \n",
    "    if merged_train_state is not None:\n",
    "        # Analyze merged state\n",
    "        print(\"\\n3Ô∏è‚É£ MERGED MODEL (after partial loading)\")\n",
    "        merged_total = analyze_parameter_tree(merged_train_state.params, \"Merged\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95459db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PARAMETER COPYING VERIFICATION\n",
      "============================================================\n",
      "üîç Checking if copied parameters are identical:\n",
      "\n",
      "Comparing old.classifier vs merged.classifier:\n",
      "\n",
      "Comparing old.classifier.Embed_0 vs merged.classifier.Embed_0:\n",
      "  ‚úÖ Exact match at embedding: shape (1025, 64)\n",
      "\n",
      "Comparing old.classifier.Transformer_0 vs merged.classifier.Transformer_0:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4 vs merged.classifier.Transformer_0.TransformerBlock_4:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.attention vs merged.classifier.Transformer_0.TransformerBlock_4.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_4.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_4.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_4.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_4.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_4.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_4.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_4.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_4.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_4.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_4.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6 vs merged.classifier.Transformer_0.TransformerBlock_6:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.attention vs merged.classifier.Transformer_0.TransformerBlock_6.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_6.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_6.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_6.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_6.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_6.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_6.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_6.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_6.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_6.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_6.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9 vs merged.classifier.Transformer_0.TransformerBlock_9:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.attention vs merged.classifier.Transformer_0.TransformerBlock_9.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_9.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_9.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_9.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_9.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_9.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_9.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_9.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_9.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_9.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_9.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10 vs merged.classifier.Transformer_0.TransformerBlock_10:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.attention vs merged.classifier.Transformer_0.TransformerBlock_10.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_10.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_10.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_10.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_10.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_10.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_10.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_10.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_10.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_10.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_10.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0 vs merged.classifier.Transformer_0.TransformerBlock_0:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.attention vs merged.classifier.Transformer_0.TransformerBlock_0.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_0.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_0.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_0.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_0.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_0.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_0.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_0.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_0.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_0.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_0.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3 vs merged.classifier.Transformer_0.TransformerBlock_3:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.attention vs merged.classifier.Transformer_0.TransformerBlock_3.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_3.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_3.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_3.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_3.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_3.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_3.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_3.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_3.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_3.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_3.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11 vs merged.classifier.Transformer_0.TransformerBlock_11:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.attention vs merged.classifier.Transformer_0.TransformerBlock_11.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_11.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_11.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_11.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_11.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_11.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_11.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_11.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_11.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_11.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_11.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7 vs merged.classifier.Transformer_0.TransformerBlock_7:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.attention vs merged.classifier.Transformer_0.TransformerBlock_7.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_7.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_7.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_7.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_7.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_7.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_7.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_7.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_7.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_7.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_7.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.Dense_1 vs merged.classifier.Transformer_0.Dense_1:\n",
      "  ‚úÖ Exact match at bias: shape (2048,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 2048)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5 vs merged.classifier.Transformer_0.TransformerBlock_5:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.attention vs merged.classifier.Transformer_0.TransformerBlock_5.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_5.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_5.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_5.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_5.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_5.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_5.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_5.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_5.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_5.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_5.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.Dense_0 vs merged.classifier.Transformer_0.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (1024,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1 vs merged.classifier.Transformer_0.TransformerBlock_1:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.attention vs merged.classifier.Transformer_0.TransformerBlock_1.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_1.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_1.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_1.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_1.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_1.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_1.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_1.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_1.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_1.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_1.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.Dense_2 vs merged.classifier.Transformer_0.Dense_2:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2 vs merged.classifier.Transformer_0.TransformerBlock_2:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.attention vs merged.classifier.Transformer_0.TransformerBlock_2.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_2.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_2.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_2.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_2.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_2.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_2.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_2.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_2.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_2.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_2.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8 vs merged.classifier.Transformer_0.TransformerBlock_8:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.attention vs merged.classifier.Transformer_0.TransformerBlock_8.attention:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.attention.wv vs merged.classifier.Transformer_0.TransformerBlock_8.attention.wv:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.attention.wo vs merged.classifier.Transformer_0.TransformerBlock_8.attention.wo:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.attention.wk vs merged.classifier.Transformer_0.TransformerBlock_8.attention.wk:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.attention.wq vs merged.classifier.Transformer_0.TransformerBlock_8.attention.wq:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.feed_forward vs merged.classifier.Transformer_0.TransformerBlock_8.feed_forward:\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.feed_forward.w1 vs merged.classifier.Transformer_0.TransformerBlock_8.feed_forward.w1:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.feed_forward.w3 vs merged.classifier.Transformer_0.TransformerBlock_8.feed_forward.w3:\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 2816)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.feed_forward.w2 vs merged.classifier.Transformer_0.TransformerBlock_8.feed_forward.w2:\n",
      "  ‚úÖ Exact match at kernel: shape (2816, 1024)\n",
      "\n",
      "Comparing old.classifier.Transformer_0.TransformerBlock_8.Dense_0 vs merged.classifier.Transformer_0.TransformerBlock_8.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (6144,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 6144)\n",
      "\n",
      "Comparing old.classifier.CondEmbedding_0 vs merged.classifier.CondEmbedding_0:\n",
      "\n",
      "Comparing old.classifier.CondEmbedding_0.dense0 vs merged.classifier.CondEmbedding_0.dense0:\n",
      "  ‚úÖ Exact match at bias: shape (256,)\n",
      "  ‚úÖ Exact match at kernel: shape (128, 256)\n",
      "\n",
      "Comparing old.classifier.CondEmbedding_0.Dense_0 vs merged.classifier.CondEmbedding_0.Dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (64,)\n",
      "  ‚úÖ Exact match at kernel: shape (256, 64)\n",
      "‚úÖ classifier: Parameters copied correctly\n",
      "\n",
      "Comparing old.cond_embeddings vs merged.cond_embeddings:\n",
      "\n",
      "Comparing old.cond_embeddings.cond_dense_1 vs merged.cond_embeddings.cond_dense_1:\n",
      "  ‚úÖ Exact match at bias: shape (128,)\n",
      "  ‚úÖ Exact match at kernel: shape (1024, 128)\n",
      "\n",
      "Comparing old.cond_embeddings.cond_dense_0 vs merged.cond_embeddings.cond_dense_0:\n",
      "  ‚úÖ Exact match at bias: shape (1024,)\n",
      "  ‚úÖ Exact match at kernel: shape (2048, 1024)\n",
      "\n",
      "Comparing old.cond_embeddings.cond_dense_out vs merged.cond_embeddings.cond_dense_out:\n",
      "  ‚úÖ Exact match at bias: shape (64,)\n",
      "  ‚úÖ Exact match at kernel: shape (64, 64)\n",
      "\n",
      "Comparing old.cond_embeddings.cond_dense_2 vs merged.cond_embeddings.cond_dense_2:\n",
      "  ‚úÖ Exact match at bias: shape (64,)\n",
      "  ‚úÖ Exact match at kernel: shape (128, 64)\n",
      "‚úÖ cond_embeddings: Parameters copied correctly\n",
      "\n",
      "üîç Checking new parameters are properly initialized:\n",
      "  fp_adapter:\n",
      "    ‚úÖ Properly initialized\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify parameter copying accuracy\n",
    "print(\"‚úÖ PARAMETER COPYING VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def compare_param_trees(tree1, tree2, name1, name2, tolerance=1e-15):\n",
    "    \"\"\"Compare two parameter trees for exact matches.\"\"\"\n",
    "    print(f\"\\nComparing {name1} vs {name2}:\")\n",
    "    \n",
    "    def compare_arrays(arr1, arr2, path=\"\"):\n",
    "        if arr1.shape != arr2.shape:\n",
    "            print(f\"  ‚ùå Shape mismatch at {path}: {arr1.shape} vs {arr2.shape}\")\n",
    "            return False\n",
    "        \n",
    "        if jnp.allclose(arr1, arr2, rtol=tolerance, atol=tolerance):\n",
    "            print(f\"  ‚úÖ Exact match at {path}: shape {arr1.shape}\")\n",
    "            return True\n",
    "        else:\n",
    "            max_diff = float(jnp.max(jnp.abs(arr1 - arr2)))\n",
    "            mean_diff = float(jnp.mean(jnp.abs(arr1 - arr2)))\n",
    "            print(f\"  ‚ö†Ô∏è  Difference at {path}: max={max_diff:.2e}, mean={mean_diff:.2e}\")\n",
    "            return False\n",
    "    \n",
    "    all_match = True\n",
    "    \n",
    "    # Compare common keys\n",
    "    common_keys = set(tree1.keys()) & set(tree2.keys())\n",
    "    for key in common_keys:\n",
    "        val1, val2 = tree1[key], tree2[key]\n",
    "        \n",
    "        if isinstance(val1, dict) and isinstance(val2, dict):\n",
    "            # Recursively compare sub-dictionaries\n",
    "            sub_match = compare_param_trees(val1, val2, f\"{name1}.{key}\", f\"{name2}.{key}\", tolerance)\n",
    "            all_match = all_match and sub_match\n",
    "        elif hasattr(val1, 'shape') and hasattr(val2, 'shape'):\n",
    "            # Compare arrays\n",
    "            match = compare_arrays(val1, val2, key)\n",
    "            all_match = all_match and match\n",
    "    \n",
    "    # Report keys that exist in only one tree\n",
    "    only_in_1 = set(tree1.keys()) - set(tree2.keys())\n",
    "    only_in_2 = set(tree2.keys()) - set(tree1.keys())\n",
    "    \n",
    "    if only_in_1:\n",
    "        print(f\"  üìù Only in {name1}: {only_in_1}\")\n",
    "    if only_in_2:\n",
    "        print(f\"  üìù Only in {name2}: {only_in_2}\")\n",
    "    \n",
    "    return all_match\n",
    "\n",
    "if loaded_old_train_state is not None and merged_train_state is not None:\n",
    "    # Verify that copied parameters are identical\n",
    "    print(\"üîç Checking if copied parameters are identical:\")\n",
    "    \n",
    "    # Compare parameters that should have been copied\n",
    "    for param_name in params_copied:\n",
    "        if param_name in loaded_old_train_state.params and param_name in merged_train_state.params:\n",
    "            params_match = compare_param_trees(\n",
    "                loaded_old_train_state.params[param_name],\n",
    "                merged_train_state.params[param_name],\n",
    "                f\"old.{param_name}\",\n",
    "                f\"merged.{param_name}\"\n",
    "            )\n",
    "            \n",
    "            if params_match:\n",
    "                print(f\"‚úÖ {param_name}: Parameters copied correctly\")\n",
    "            else:\n",
    "                print(f\"‚ùå {param_name}: Parameters may not have copied correctly\")\n",
    "    \n",
    "    # Verify that new parameters are different from any old parameters\n",
    "    print(f\"\\nüîç Checking new parameters are properly initialized:\")\n",
    "    for param_name in params_new:\n",
    "        if param_name in merged_train_state.params:\n",
    "            param_vals = merged_train_state.params[param_name]\n",
    "            \n",
    "            # Check if it's properly initialized (not all zeros, not NaN)\n",
    "            def check_initialization(arr, path=\"\"):\n",
    "                if hasattr(arr, 'shape'):\n",
    "                    mean_val = float(jnp.mean(arr))\n",
    "                    std_val = float(jnp.std(arr))\n",
    "                    has_nans = bool(jnp.any(jnp.isnan(arr)))\n",
    "                    all_zeros = bool(jnp.all(arr == 0))\n",
    "                    \n",
    "                    print(f\"    {path}: mean={mean_val:.6f}, std={std_val:.6f}, \"\n",
    "                          f\"has_nans={has_nans}, all_zeros={all_zeros}\")\n",
    "                    \n",
    "                    return not (has_nans or all_zeros or std_val < 1e-8)\n",
    "                return True\n",
    "            \n",
    "            print(f\"  {param_name}:\")\n",
    "            if isinstance(param_vals, dict):\n",
    "                init_ok = True\n",
    "                for subkey, subval in param_vals.items():\n",
    "                    init_ok = init_ok and check_initialization(subval, subkey)\n",
    "            else:\n",
    "                init_ok = check_initialization(param_vals)\n",
    "            \n",
    "            if init_ok:\n",
    "                print(f\"    ‚úÖ Properly initialized\")\n",
    "            else:\n",
    "                print(f\"    ‚ö†Ô∏è  May have initialization issues\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot verify parameter copying - missing required states\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9604cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßä FROZEN BEHAVIOR ANALYSIS\n",
      "============================================================\n",
      "Testing frozen train state behavior...\n",
      "New optimizer: GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7e7124d4c180>, update=<function chain.<locals>.update_fn at 0x7e7124d4c220>)\n",
      "\n",
      "Optimizer state structure: (EmptyState(), (ScaleByAdamState(count='ArrayImpl', mu={'classifier': {'CondEmbedding_0': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'dense0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}}, 'Embed_0': {'embedding': 'ArrayImpl'}, 'Transformer_0': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'Dense_1': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'Dense_2': {'kernel': 'ArrayImpl'}, 'TransformerBlock_0': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_1': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_10': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_11': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_2': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_3': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_4': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_5': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_6': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_7': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_8': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_9': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}}}, 'cond_embeddings': {'cond_dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'cond_dense_1': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'cond_dense_2': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'cond_dense_out': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}}, 'fp_adapter': {'fingerprint_adapter_dense': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'fingerprint_adapter_out': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}}}, nu={'classifier': {'CondEmbedding_0': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'dense0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}}, 'Embed_0': {'embedding': 'ArrayImpl'}, 'Transformer_0': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'Dense_1': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'Dense_2': {'kernel': 'ArrayImpl'}, 'TransformerBlock_0': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_1': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_10': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_11': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_2': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_3': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_4': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_5': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_6': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_7': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_8': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}, 'TransformerBlock_9': {'Dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'attention': {'wk': {'kernel': 'ArrayImpl'}, 'wo': {'kernel': 'ArrayImpl'}, 'wq': {'kernel': 'ArrayImpl'}, 'wv': {'kernel': 'ArrayImpl'}}, 'feed_forward': {'w1': {'kernel': 'ArrayImpl'}, 'w2': {'kernel': 'ArrayImpl'}, 'w3': {'kernel': 'ArrayImpl'}}}}}, 'cond_embeddings': {'cond_dense_0': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'cond_dense_1': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'cond_dense_2': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'cond_dense_out': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}}, 'fp_adapter': {'fingerprint_adapter_dense': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}, 'fingerprint_adapter_out': {'bias': 'ArrayImpl', 'kernel': 'ArrayImpl'}}}), EmptyState(), ScaleByScheduleState(count='ArrayImpl')), MaskedState(inner_state=EmptyState()))\n",
      "\n",
      "Looking for freeze information in optimizer...\n",
      "  üßä Found MaskedState at [2]: MaskedState(inner_state=EmptyState())\n",
      "    Inner state: EmptyState()\n",
      "\n",
      "üß™ Testing parameter update behavior...\n",
      "‚úÖ Optimizer update successful\n",
      "Parameter update analysis:\n",
      "  classifier.CondEmbedding_0.Dense_0.bias: grad_norm=0.080000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.CondEmbedding_0.Dense_0.kernel: grad_norm=1.280000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.CondEmbedding_0.dense0.bias: grad_norm=0.160000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.CondEmbedding_0.dense0.kernel: grad_norm=1.810194, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Embed_0.embedding: grad_norm=2.561250, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.Dense_0.bias: grad_norm=0.320000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.Dense_0.kernel: grad_norm=2.560001, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.Dense_1.bias: grad_norm=0.452548, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.Dense_1.kernel: grad_norm=3.620388, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.Dense_2.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_0.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_1.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_10.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_11.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_2.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_3.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_4.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_5.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_6.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_7.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_8.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.Dense_0.bias: grad_norm=0.783837, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.Dense_0.kernel: grad_norm=6.270695, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wk.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wo.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wq.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wv.kernel: grad_norm=10.240003, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.feed_forward.w1.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.feed_forward.w2.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  classifier.Transformer_0.TransformerBlock_9.feed_forward.w3.kernel: grad_norm=16.981123, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_0.bias: grad_norm=0.320000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_0.kernel: grad_norm=14.481551, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_1.bias: grad_norm=0.113137, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_1.kernel: grad_norm=3.620388, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_2.bias: grad_norm=0.080000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_2.kernel: grad_norm=0.905097, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_out.bias: grad_norm=0.080000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings.cond_dense_out.kernel: grad_norm=0.640000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  fp_adapter.fingerprint_adapter_dense.bias: grad_norm=0.640000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  fp_adapter.fingerprint_adapter_dense.kernel: grad_norm=40.960011, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  fp_adapter.fingerprint_adapter_out.bias: grad_norm=0.640000, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  fp_adapter.fingerprint_adapter_out.kernel: grad_norm=40.960011, update_norm=0.000000, ratio=0.000000 üßä FROZEN\n",
      "\n",
      "High-level parameter group analysis:\n",
      "  classifier: total_grad=126.608932, total_update=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings: total_grad=14.972701, total_update=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  fp_adapter: total_grad=57.933586, total_update=0.000000, ratio=0.000000 üßä FROZEN\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test frozen behavior and optimizer masks\n",
    "print(\"üßä FROZEN BEHAVIOR ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False):\n",
    "    print(\"Testing frozen train state behavior...\")\n",
    "    \n",
    "    # Let's examine the optimizer state to see what's frozen\n",
    "    print(f\"New optimizer: {new_optimizer}\")\n",
    "    \n",
    "    # Check if we can access the freeze mask from the optimizer\n",
    "    # The freeze mask should be in the optimizer chain\n",
    "    try:\n",
    "        # Initialize optimizer state to examine structure\n",
    "        dummy_params = new_train_state.params\n",
    "        opt_state = new_optimizer.init(dummy_params)\n",
    "        \n",
    "        print(f\"\\nOptimizer state structure: {jax.tree_util.tree_map(lambda x: type(x).__name__, opt_state)}\")\n",
    "        \n",
    "        # Try to find the freeze mask - look specifically for MaskedState\n",
    "        print(\"\\nLooking for freeze information in optimizer...\")\n",
    "        \n",
    "        def find_freeze_info(tree, path=\"\"):\n",
    "            if hasattr(tree, '__class__') and 'Masked' in str(tree.__class__):\n",
    "                print(f\"  üßä Found MaskedState at {path}: {tree}\")\n",
    "                if hasattr(tree, 'inner_state'):\n",
    "                    print(f\"    Inner state: {tree.inner_state}\")\n",
    "            \n",
    "            if isinstance(tree, (tuple, list)):\n",
    "                for i, item in enumerate(tree):\n",
    "                    find_freeze_info(item, f\"{path}[{i}]\")\n",
    "            elif isinstance(tree, dict):\n",
    "                for key, value in tree.items():\n",
    "                    find_freeze_info(value, f\"{path}.{key}\" if path else key)\n",
    "            elif hasattr(tree, '__dict__'):\n",
    "                for attr_name in dir(tree):\n",
    "                    if not attr_name.startswith('_') and attr_name in ['inner_state', 'mask']:\n",
    "                        try:\n",
    "                            attr_value = getattr(tree, attr_name)\n",
    "                            print(f\"  Found {attr_name} at {path}: {type(attr_value)}\")\n",
    "                        except:\n",
    "                            pass\n",
    "        \n",
    "        find_freeze_info(opt_state)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error examining optimizer state: {e}\")\n",
    "    \n",
    "    # Test what happens when we try to update frozen parameters\n",
    "    print(\"\\nüß™ Testing parameter update behavior...\")\n",
    "    \n",
    "    # Create some dummy gradients\n",
    "    dummy_grads = jax.tree_util.tree_map(\n",
    "        lambda x: jnp.ones_like(x) * 0.01,  # Small gradient\n",
    "        new_train_state.params\n",
    "    )\n",
    "    \n",
    "    # Apply one optimizer step\n",
    "    try:\n",
    "        updates, new_opt_state = new_optimizer.update(\n",
    "            dummy_grads, \n",
    "            new_train_state.opt_state, \n",
    "            new_train_state.params\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Optimizer update successful\")\n",
    "        \n",
    "        # Check which parameters would actually be updated\n",
    "        print(\"Parameter update analysis:\")\n",
    "        \n",
    "        def analyze_updates(grads_tree, updates_tree, path=\"\"):\n",
    "            \"\"\"Recursively analyze parameter updates.\"\"\"\n",
    "            if isinstance(grads_tree, dict) and isinstance(updates_tree, dict):\n",
    "                for key in grads_tree.keys():\n",
    "                    if key in updates_tree:\n",
    "                        new_path = f\"{path}.{key}\" if path else key\n",
    "                        analyze_updates(grads_tree[key], updates_tree[key], new_path)\n",
    "            elif hasattr(grads_tree, 'shape') and hasattr(updates_tree, 'shape'):\n",
    "                # These are actual arrays\n",
    "                grad_norm = float(jnp.linalg.norm(jnp.ravel(grads_tree)))\n",
    "                update_norm = float(jnp.linalg.norm(jnp.ravel(updates_tree)))\n",
    "                ratio = update_norm / grad_norm if grad_norm > 0 else 0\n",
    "                \n",
    "                if update_norm < 1e-10:\n",
    "                    status = \"üßä FROZEN\"\n",
    "                elif ratio < 1e-6:\n",
    "                    status = \"üîí MOSTLY FROZEN\"\n",
    "                else:\n",
    "                    status = \"üî• ACTIVE\"\n",
    "                \n",
    "                print(f\"  {path}: grad_norm={grad_norm:.6f}, update_norm={update_norm:.6f}, ratio={ratio:.6f} {status}\")\n",
    "        \n",
    "        analyze_updates(dummy_grads, updates)\n",
    "        \n",
    "        # Also check the high-level parameter groups\n",
    "        print(f\"\\nHigh-level parameter group analysis:\")\n",
    "        for param_group in ['classifier', 'cond_embeddings', 'fp_adapter']:\n",
    "            if param_group in dummy_grads and param_group in updates:\n",
    "                # Calculate total norms for each parameter group\n",
    "                grad_leaves = jax.tree_util.tree_leaves(dummy_grads[param_group])\n",
    "                update_leaves = jax.tree_util.tree_leaves(updates[param_group])\n",
    "                \n",
    "                total_grad_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in grad_leaves)))\n",
    "                total_update_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in update_leaves)))\n",
    "                ratio = total_update_norm / total_grad_norm if total_grad_norm > 0 else 0\n",
    "                \n",
    "                if total_update_norm < 1e-8:\n",
    "                    status = \"üßä FROZEN\"\n",
    "                elif ratio < 1e-4:\n",
    "                    status = \"üîí MOSTLY FROZEN\"\n",
    "                else:\n",
    "                    status = \"üî• ACTIVE\"\n",
    "                \n",
    "                print(f\"  {param_group}: total_grad={total_grad_norm:.6f}, total_update={total_update_norm:.6f}, ratio={ratio:.6f} {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during optimizer update: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"New model is not in frozen mode - skipping frozen behavior analysis\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the actual partial_load_utils function\n",
    "print(\"üîß TESTING ACTUAL PARTIAL LOADING FUNCTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if loaded_old_train_state is not None:\n",
    "    try:\n",
    "        # Test if we should use partial loading according to the utility\n",
    "        should_partial_load = partial_load_utils.should_use_partial_loading(new_config)\n",
    "        print(f\"Should use partial loading according to config: {should_partial_load}\")\n",
    "        \n",
    "        # Test the actual partial loading function if available\n",
    "        if hasattr(partial_load_utils, 'partial_load_checkpoint'):\n",
    "            print(\"\\nTesting partial_load_checkpoint function...\")\n",
    "            \n",
    "            # We'll need to create a mock checkpoint manager for this test\n",
    "            # since partial_load_checkpoint expects to load from a checkpoint manager\n",
    "            \n",
    "            # For now, let's just test the logic by examining the function\n",
    "            import inspect\n",
    "            source = inspect.getsource(partial_load_utils.partial_load_checkpoint)\n",
    "            print(\"Function signature analysis:\")\n",
    "            sig = inspect.signature(partial_load_utils.partial_load_checkpoint)\n",
    "            print(f\"Parameters: {list(sig.parameters.keys())}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing partial loading function: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Cannot test partial loading function - no old checkpoint available\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e52ac4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç FREEZE MASK ANALYSIS\n",
      "============================================================\n",
      "Analyzing the freeze mask logic from create_frozen_train_state...\n",
      "Freeze mask analysis:\n",
      "classifier.CondEmbedding_0.Dense_0.bias: üßä FROZEN (shape: (64,), params: 64)\n",
      "classifier.CondEmbedding_0.Dense_0.kernel: üßä FROZEN (shape: (256, 64), params: 16,384)\n",
      "classifier.CondEmbedding_0.dense0.bias: üßä FROZEN (shape: (256,), params: 256)\n",
      "classifier.CondEmbedding_0.dense0.kernel: üßä FROZEN (shape: (128, 256), params: 32,768)\n",
      "classifier.Embed_0.embedding: üßä FROZEN (shape: (1025, 64), params: 65,600)\n",
      "classifier.Transformer_0.Dense_0.bias: üßä FROZEN (shape: (1024,), params: 1,024)\n",
      "classifier.Transformer_0.Dense_0.kernel: üßä FROZEN (shape: (64, 1024), params: 65,536)\n",
      "classifier.Transformer_0.Dense_1.bias: üßä FROZEN (shape: (2048,), params: 2,048)\n",
      "classifier.Transformer_0.Dense_1.kernel: üßä FROZEN (shape: (64, 2048), params: 131,072)\n",
      "classifier.Transformer_0.Dense_2.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_0.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_0.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_0.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_0.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_0.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_0.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_0.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_0.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_0.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_1.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_1.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_1.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_1.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_1.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_1.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_1.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_1.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_1.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_10.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_10.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_10.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_10.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_10.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_10.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_10.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_10.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_10.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_11.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_11.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_11.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_11.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_11.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_11.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_11.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_11.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_11.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_2.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_2.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_2.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_2.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_2.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_2.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_2.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_2.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_2.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_3.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_3.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_3.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_3.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_3.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_3.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_3.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_3.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_3.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_4.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_4.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_4.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_4.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_4.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_4.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_4.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_4.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_4.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_5.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_5.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_5.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_5.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_5.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_5.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_5.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_5.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_5.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_6.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_6.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_6.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_6.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_6.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_6.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_6.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_6.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_6.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_7.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_7.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_7.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_7.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_7.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_7.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_7.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_7.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_7.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_8.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_8.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_8.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_8.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_8.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_8.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_8.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_8.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_8.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_9.Dense_0.bias: üßä FROZEN (shape: (6144,), params: 6,144)\n",
      "classifier.Transformer_0.TransformerBlock_9.Dense_0.kernel: üßä FROZEN (shape: (64, 6144), params: 393,216)\n",
      "classifier.Transformer_0.TransformerBlock_9.attention.wk.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_9.attention.wo.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_9.attention.wq.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_9.attention.wv.kernel: üßä FROZEN (shape: (1024, 1024), params: 1,048,576)\n",
      "classifier.Transformer_0.TransformerBlock_9.feed_forward.w1.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_9.feed_forward.w2.kernel: üßä FROZEN (shape: (2816, 1024), params: 2,883,584)\n",
      "classifier.Transformer_0.TransformerBlock_9.feed_forward.w3.kernel: üßä FROZEN (shape: (1024, 2816), params: 2,883,584)\n",
      "cond_embeddings.cond_dense_0.bias: üî• TRAINABLE (shape: (1024,), params: 1,024)\n",
      "cond_embeddings.cond_dense_0.kernel: üî• TRAINABLE (shape: (2048, 1024), params: 2,097,152)\n",
      "cond_embeddings.cond_dense_1.bias: üßä FROZEN (shape: (128,), params: 128)\n",
      "cond_embeddings.cond_dense_1.kernel: üßä FROZEN (shape: (1024, 128), params: 131,072)\n",
      "cond_embeddings.cond_dense_2.bias: üßä FROZEN (shape: (64,), params: 64)\n",
      "cond_embeddings.cond_dense_2.kernel: üßä FROZEN (shape: (128, 64), params: 8,192)\n",
      "cond_embeddings.cond_dense_out.bias: üßä FROZEN (shape: (64,), params: 64)\n",
      "cond_embeddings.cond_dense_out.kernel: üßä FROZEN (shape: (64, 64), params: 4,096)\n",
      "fp_adapter.fingerprint_adapter_dense.bias: üî• TRAINABLE (shape: (4096,), params: 4,096)\n",
      "fp_adapter.fingerprint_adapter_dense.kernel: üî• TRAINABLE (shape: (4096, 4096), params: 16,777,216)\n",
      "fp_adapter.fingerprint_adapter_out.bias: üî• TRAINABLE (shape: (4096,), params: 4,096)\n",
      "fp_adapter.fingerprint_adapter_out.kernel: üî• TRAINABLE (shape: (4096, 4096), params: 16,777,216)\n",
      "\n",
      "Parameter count summary:\n",
      "  üßä Frozen parameters: 160,439,936 (81.8%)\n",
      "  üî• Trainable parameters: 35,660,800 (18.2%)\n",
      "  üìä Total parameters: 196,100,736\n",
      "\n",
      "Expected trainable components:\n",
      "  - fp_adapter: Should be trainable (new fingerprint processing layers)\n",
      "  - cond_embeddings.cond_dense_0: Should be trainable (first conditioning layer)\n",
      "  - Everything else: Should be frozen (pretrained weights)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Examine the freeze mask from train.py\n",
    "print(\"üîç FREEZE MASK ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False):\n",
    "    print(\"Analyzing the freeze mask logic from create_frozen_train_state...\")\n",
    "    \n",
    "    # Let's recreate the freeze mask logic to understand what should be frozen\n",
    "    from flax import traverse_util\n",
    "    \n",
    "    def _should_freeze(path, v) -> bool:\n",
    "        \"\"\"Recreate the freeze logic from train.py\"\"\"\n",
    "        # Based on the train.py code, this function should return True for frozen params\n",
    "        if \"fp_adapter\" in path:\n",
    "            return False  # fp_adapter should NOT be frozen (can be trained)\n",
    "        return True  # Everything else should be frozen\n",
    "    \n",
    "    # Create the freeze mask\n",
    "    mask = traverse_util.path_aware_map(_should_freeze, new_train_state.params)\n",
    "    \n",
    "    # The train.py code also manually sets some parameters to False (trainable)\n",
    "    if 'cond_embeddings' in mask and 'cond_dense_0' in mask['cond_embeddings']:\n",
    "        mask['cond_embeddings']['cond_dense_0']['kernel'] = False\n",
    "        mask['cond_embeddings']['cond_dense_0']['bias'] = False\n",
    "    \n",
    "    print(\"Freeze mask analysis:\")\n",
    "    \n",
    "    def print_mask(mask_tree, params_tree, path=\"\", indent=0):\n",
    "        \"\"\"Print the freeze mask with parameter info.\"\"\"\n",
    "        prefix = \"  \" * indent\n",
    "        \n",
    "        if isinstance(mask_tree, dict) and isinstance(params_tree, dict):\n",
    "            for key in mask_tree.keys():\n",
    "                if key in params_tree:\n",
    "                    new_path = f\"{path}.{key}\" if path else key\n",
    "                    print_mask(mask_tree[key], params_tree[key], new_path, indent)\n",
    "        elif isinstance(mask_tree, bool):\n",
    "            # This is a leaf node with a boolean mask value\n",
    "            if hasattr(params_tree, 'shape'):\n",
    "                param_count = int(jnp.prod(jnp.array(params_tree.shape)))\n",
    "                status = \"üßä FROZEN\" if mask_tree else \"üî• TRAINABLE\"\n",
    "                print(f\"{prefix}{path}: {status} (shape: {params_tree.shape}, params: {param_count:,})\")\n",
    "    \n",
    "    print_mask(mask, new_train_state.params)\n",
    "    \n",
    "    # Count frozen vs trainable parameters\n",
    "    def count_params(mask_tree, params_tree):\n",
    "        \"\"\"Count frozen vs trainable parameters.\"\"\"\n",
    "        frozen_count = 0\n",
    "        trainable_count = 0\n",
    "        \n",
    "        def count_recursive(mask_val, param_val):\n",
    "            nonlocal frozen_count, trainable_count\n",
    "            \n",
    "            if isinstance(mask_val, dict) and isinstance(param_val, dict):\n",
    "                for key in mask_val.keys():\n",
    "                    if key in param_val:\n",
    "                        count_recursive(mask_val[key], param_val[key])\n",
    "            elif isinstance(mask_val, bool) and hasattr(param_val, 'shape'):\n",
    "                param_count = int(jnp.prod(jnp.array(param_val.shape)))\n",
    "                if mask_val:\n",
    "                    frozen_count += param_count\n",
    "                else:\n",
    "                    trainable_count += param_count\n",
    "        \n",
    "        count_recursive(mask_tree, params_tree)\n",
    "        return frozen_count, trainable_count\n",
    "    \n",
    "    frozen_params, trainable_params = count_params(mask, new_train_state.params)\n",
    "    total_params = frozen_params + trainable_params\n",
    "    \n",
    "    print(f\"\\nParameter count summary:\")\n",
    "    print(f\"  üßä Frozen parameters: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")\n",
    "    print(f\"  üî• Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "    print(f\"  üìä Total parameters: {total_params:,}\")\n",
    "    \n",
    "    # Verify this matches what we expect for finetuning\n",
    "    print(f\"\\nExpected trainable components:\")\n",
    "    print(f\"  - fp_adapter: Should be trainable (new fingerprint processing layers)\")\n",
    "    print(f\"  - cond_embeddings.cond_dense_0: Should be trainable (first conditioning layer)\")\n",
    "    print(f\"  - Everything else: Should be frozen (pretrained weights)\")\n",
    "\n",
    "else:\n",
    "    print(\"Model is not in frozen mode - no freeze mask to analyze\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1bd5384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß DEBUGGING FREEZE MASK IN OPTIMIZER\n",
      "============================================================\n",
      "Examining the actual freeze mask used by the optimizer...\n",
      "Optimizer state structure: <class 'tuple'>\n",
      "Optimizer state has 3 components:\n",
      "  Component 0: <class 'optax._src.base.EmptyState'>\n",
      "  Component 1: <class 'tuple'>\n",
      "  Component 2: <class 'optax.transforms._masking.MaskedState'>\n",
      "    üßä Found MaskedState at component 2\n",
      "    ‚ö†Ô∏è  No mask attribute found in MaskedState\n",
      "\n",
      "üîç MANUAL FREEZE MASK RECREATION\n",
      "Recreating the freeze logic step by step...\n",
      "  Creating initial mask with path_aware_map:\n",
      "    classifier.CondEmbedding_0.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.CondEmbedding_0.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.CondEmbedding_0.dense0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.CondEmbedding_0.dense0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Embed_0.embedding: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.Dense_1.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.Dense_1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.Dense_2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_0.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_1.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_10.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_11.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_2.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_3.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_4.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_5.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_6.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_7.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_8.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.Dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.Dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.attention.wk.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.attention.wo.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.attention.wq.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.attention.wv.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.feed_forward.w1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.feed_forward.w2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    classifier.Transformer_0.TransformerBlock_9.feed_forward.w3.kernel: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_0.bias: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_0.kernel: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_1.bias: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_1.kernel: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_2.bias: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_2.kernel: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_out.bias: no fp_adapter -> FROZEN (True)\n",
      "    cond_embeddings.cond_dense_out.kernel: no fp_adapter -> FROZEN (True)\n",
      "    fp_adapter.fingerprint_adapter_dense.bias: fp_adapter found -> TRAINABLE (False)\n",
      "    fp_adapter.fingerprint_adapter_dense.kernel: fp_adapter found -> TRAINABLE (False)\n",
      "    fp_adapter.fingerprint_adapter_out.bias: fp_adapter found -> TRAINABLE (False)\n",
      "    fp_adapter.fingerprint_adapter_out.kernel: fp_adapter found -> TRAINABLE (False)\n",
      "  \n",
      "  Applying manual overrides:\n",
      "    Setting cond_embeddings.cond_dense_0.kernel to TRAINABLE\n",
      "    Setting cond_embeddings.cond_dense_0.bias to TRAINABLE\n",
      "  \n",
      "  Creating freezer with optax.transforms.freeze(mask)\n",
      "  \n",
      "  Testing freezer behavior:\n",
      "    Freeze results:\n",
      "      classifier: update_norm=0.000000 üßä FROZEN\n",
      "      cond_embeddings: update_norm=14.485167 üî• TRAINABLE\n",
      "      fp_adapter: update_norm=57.933586 üî• TRAINABLE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Debug the actual freeze mask in the optimizer\n",
    "print(\"üîß DEBUGGING FREEZE MASK IN OPTIMIZER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Import optax for freeze functionality\n",
    "import optax\n",
    "\n",
    "if new_config.get('frozen', False) and new_train_state is not None:\n",
    "    print(\"Examining the actual freeze mask used by the optimizer...\")\n",
    "    \n",
    "    # Try to extract the freeze mask from the optimizer state\n",
    "    opt_state = new_train_state.opt_state\n",
    "    \n",
    "    # The freeze mask should be in the MaskedState part of the optimizer\n",
    "    print(f\"Optimizer state structure: {type(opt_state)}\")\n",
    "    \n",
    "    if hasattr(opt_state, '__iter__') and len(opt_state) > 0:\n",
    "        print(f\"Optimizer state has {len(opt_state)} components:\")\n",
    "        for i, component in enumerate(opt_state):\n",
    "            print(f\"  Component {i}: {type(component)}\")\n",
    "            \n",
    "            # Look for MaskedState which should contain the freeze mask\n",
    "            if hasattr(component, '__class__') and 'Masked' in str(component.__class__):\n",
    "                print(f\"    üßä Found MaskedState at component {i}\")\n",
    "                \n",
    "                # Try to access the mask\n",
    "                if hasattr(component, 'mask'):\n",
    "                    print(f\"    Mask type: {type(component.mask)}\")\n",
    "                    \n",
    "                    # Print a summary of the mask\n",
    "                    if component.mask is not None:\n",
    "                        def print_mask_summary(mask_tree, path=\"\"):\n",
    "                            \"\"\"Print a summary of the freeze mask.\"\"\"\n",
    "                            if isinstance(mask_tree, dict):\n",
    "                                for key, value in mask_tree.items():\n",
    "                                    new_path = f\"{path}.{key}\" if path else key\n",
    "                                    print_mask_summary(value, new_path)\n",
    "                            elif isinstance(mask_tree, bool):\n",
    "                                status = \"üßä FROZEN\" if mask_tree else \"üî• TRAINABLE\"\n",
    "                                print(f\"      {path}: {status}\")\n",
    "                        \n",
    "                        print(\"    Actual freeze mask in optimizer:\")\n",
    "                        print_mask_summary(component.mask)\n",
    "                    else:\n",
    "                        print(\"    ‚ö†Ô∏è  Mask is None!\")\n",
    "                else:\n",
    "                    print(\"    ‚ö†Ô∏è  No mask attribute found in MaskedState\")\n",
    "    \n",
    "    # Also let's manually recreate what should happen and compare\n",
    "    print(f\"\\nüîç MANUAL FREEZE MASK RECREATION\")\n",
    "    print(\"Recreating the freeze logic step by step...\")\n",
    "    \n",
    "    # Step 1: Create the initial mask using path_aware_map\n",
    "    from flax import traverse_util\n",
    "    \n",
    "    def debug_should_freeze(path, v):\n",
    "        \"\"\"Debug version of _should_freeze\"\"\"\n",
    "        path_str = '.'.join(str(p.key) if hasattr(p, 'key') else str(p) for p in path)\n",
    "        \n",
    "        if \"fp_adapter\" in path_str:\n",
    "            print(f\"    {path_str}: fp_adapter found -> TRAINABLE (False)\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"    {path_str}: no fp_adapter -> FROZEN (True)\")\n",
    "            return True\n",
    "    \n",
    "    print(\"  Creating initial mask with path_aware_map:\")\n",
    "    mask = traverse_util.path_aware_map(debug_should_freeze, new_train_state.params)\n",
    "    \n",
    "    # Step 2: Manual overrides\n",
    "    print(\"  \\n  Applying manual overrides:\")\n",
    "    if 'cond_embeddings' in mask and 'cond_dense_0' in mask['cond_embeddings']:\n",
    "        print(\"    Setting cond_embeddings.cond_dense_0.kernel to TRAINABLE\")\n",
    "        print(\"    Setting cond_embeddings.cond_dense_0.bias to TRAINABLE\")\n",
    "        mask['cond_embeddings']['cond_dense_0']['kernel'] = False\n",
    "        mask['cond_embeddings']['cond_dense_0']['bias'] = False\n",
    "    \n",
    "    # Step 3: Create the freezer\n",
    "    print(\"  \\n  Creating freezer with optax.transforms.freeze(mask)\")\n",
    "    freezer = optax.transforms.freeze(mask)\n",
    "    \n",
    "    # Step 4: Test the freezer\n",
    "    print(\"  \\n  Testing freezer behavior:\")\n",
    "    dummy_params = new_train_state.params\n",
    "    dummy_grads = jax.tree_util.tree_map(lambda x: jnp.ones_like(x) * 0.01, dummy_params)\n",
    "    \n",
    "    # Apply freezer to gradients\n",
    "    freezer_state = freezer.init(dummy_params)\n",
    "    frozen_updates, _ = freezer.update(dummy_grads, freezer_state, dummy_params)\n",
    "    \n",
    "    # Check which updates are actually frozen\n",
    "    print(\"    Freeze results:\")\n",
    "    for param_group in ['classifier', 'cond_embeddings', 'fp_adapter']:\n",
    "        if param_group in frozen_updates:\n",
    "            update_leaves = jax.tree_util.tree_leaves(frozen_updates[param_group])\n",
    "            total_update_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in update_leaves)))\n",
    "            \n",
    "            if total_update_norm < 1e-10:\n",
    "                status = \"üßä FROZEN\"\n",
    "            else:\n",
    "                status = \"üî• TRAINABLE\"\n",
    "            \n",
    "            print(f\"      {param_group}: update_norm={total_update_norm:.6f} {status}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd54a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FP_ADAPTER FREEZE DIAGNOSTIC\n",
      "============================================================\n",
      "1Ô∏è‚É£ Checking fp_adapter existence:\n",
      "‚úÖ fp_adapter found in parameters\n",
      "   fp_adapter structure: ['fingerprint_adapter_dense', 'fingerprint_adapter_out']\n",
      "\n",
      "2Ô∏è‚É£ Testing _should_freeze logic:\n",
      "   fp_adapter.fingerprint_adapter_dense.kernel: üî• TRAINABLE\n",
      "   fp_adapter.fingerprint_adapter_out.bias: üî• TRAINABLE\n",
      "   classifier.Embed_0.embedding: üßä FROZEN\n",
      "   cond_embeddings.cond_dense_0.kernel: üßä FROZEN\n",
      "\n",
      "3Ô∏è‚É£ Creating and testing actual freeze mask:\n",
      "   fp_adapter mask values:\n",
      "     fp_adapter.fingerprint_adapter_dense.bias: üî• TRAINABLE\n",
      "     fp_adapter.fingerprint_adapter_dense.kernel: üî• TRAINABLE\n",
      "     fp_adapter.fingerprint_adapter_out.bias: üî• TRAINABLE\n",
      "     fp_adapter.fingerprint_adapter_out.kernel: üî• TRAINABLE\n",
      "\n",
      "4Ô∏è‚É£ Testing freeze behavior with dummy gradients:\n",
      "   fp_adapter: grad_norm=579.336609, update_norm=579.336609\n",
      "   ‚úÖ fp_adapter is TRAINABLE (updates are non-zero)\n",
      "   Individual fp_adapter parameter updates:\n",
      "     fingerprint_adapter_dense.bias: norm=6.400000 üî• TRAINABLE\n",
      "     fingerprint_adapter_dense.kernel: norm=409.600006 üî• TRAINABLE\n",
      "     fingerprint_adapter_out.bias: norm=6.400000 üî• TRAINABLE\n",
      "     fingerprint_adapter_out.kernel: norm=409.600006 üî• TRAINABLE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Focused fp_adapter freeze diagnostic\n",
    "print(\"üéØ FP_ADAPTER FREEZE DIAGNOSTIC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False) and new_train_state is not None:\n",
    "    import optax\n",
    "    from flax import traverse_util\n",
    "    \n",
    "    # Step 1: Check if fp_adapter exists in parameters\n",
    "    print(\"1Ô∏è‚É£ Checking fp_adapter existence:\")\n",
    "    if 'fp_adapter' in new_train_state.params:\n",
    "        print(\"‚úÖ fp_adapter found in parameters\")\n",
    "        fp_params = new_train_state.params['fp_adapter']\n",
    "        print(f\"   fp_adapter structure: {list(fp_params.keys())}\")\n",
    "    else:\n",
    "        print(\"‚ùå fp_adapter NOT found in parameters!\")\n",
    "        print(f\"   Available parameter groups: {list(new_train_state.params.keys())}\")\n",
    "    \n",
    "    # Step 2: Test the _should_freeze function logic\n",
    "    print(\"\\n2Ô∏è‚É£ Testing _should_freeze logic:\")\n",
    "    \n",
    "    def test_should_freeze(path_str):\n",
    "        if \"fp_adapter\" in path_str:\n",
    "            return False  # Should be trainable\n",
    "        return True  # Should be frozen\n",
    "    \n",
    "    test_paths = [\n",
    "        \"fp_adapter.fingerprint_adapter_dense.kernel\",\n",
    "        \"fp_adapter.fingerprint_adapter_out.bias\", \n",
    "        \"classifier.Embed_0.embedding\",\n",
    "        \"cond_embeddings.cond_dense_0.kernel\"\n",
    "    ]\n",
    "    \n",
    "    for path in test_paths:\n",
    "        should_freeze = test_should_freeze(path)\n",
    "        status = \"üßä FROZEN\" if should_freeze else \"üî• TRAINABLE\"\n",
    "        print(f\"   {path}: {status}\")\n",
    "    \n",
    "    # Step 3: Create actual freeze mask and test fp_adapter specifically\n",
    "    print(\"\\n3Ô∏è‚É£ Creating and testing actual freeze mask:\")\n",
    "    \n",
    "    def actual_should_freeze(path, v):\n",
    "        path_str = '.'.join(str(p.key) if hasattr(p, 'key') else str(p) for p in path)\n",
    "        return \"fp_adapter\" not in path_str  # True = frozen, False = trainable\n",
    "    \n",
    "    mask = traverse_util.path_aware_map(actual_should_freeze, new_train_state.params)\n",
    "    \n",
    "    # Override cond_dense_0\n",
    "    if 'cond_embeddings' in mask and 'cond_dense_0' in mask['cond_embeddings']:\n",
    "        mask['cond_embeddings']['cond_dense_0']['kernel'] = False\n",
    "        mask['cond_embeddings']['cond_dense_0']['bias'] = False\n",
    "    \n",
    "    # Check fp_adapter mask values\n",
    "    if 'fp_adapter' in mask:\n",
    "        print(\"   fp_adapter mask values:\")\n",
    "        def print_fp_mask(tree, path=\"\"):\n",
    "            if isinstance(tree, dict):\n",
    "                for k, v in tree.items():\n",
    "                    print_fp_mask(v, f\"{path}.{k}\" if path else k)\n",
    "            else:\n",
    "                status = \"üßä FROZEN\" if tree else \"üî• TRAINABLE\"\n",
    "                print(f\"     {path}: {status}\")\n",
    "        \n",
    "        print_fp_mask(mask['fp_adapter'], \"fp_adapter\")\n",
    "    \n",
    "    # Step 4: Test the freeze behavior directly\n",
    "    print(\"\\n4Ô∏è‚É£ Testing freeze behavior with dummy gradients:\")\n",
    "    \n",
    "    freezer = optax.transforms.freeze(mask)\n",
    "    dummy_grads = jax.tree_util.tree_map(lambda x: jnp.ones_like(x) * 0.1, new_train_state.params)\n",
    "    \n",
    "    freezer_state = freezer.init(new_train_state.params)\n",
    "    frozen_updates, _ = freezer.update(dummy_grads, freezer_state, new_train_state.params)\n",
    "    \n",
    "    # Check fp_adapter specifically\n",
    "    if 'fp_adapter' in frozen_updates:\n",
    "        fp_update_leaves = jax.tree_util.tree_leaves(frozen_updates['fp_adapter'])\n",
    "        fp_grad_leaves = jax.tree_util.tree_leaves(dummy_grads['fp_adapter'])\n",
    "        \n",
    "        total_grad_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in fp_grad_leaves)))\n",
    "        total_update_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in fp_update_leaves)))\n",
    "        \n",
    "        print(f\"   fp_adapter: grad_norm={total_grad_norm:.6f}, update_norm={total_update_norm:.6f}\")\n",
    "        \n",
    "        if total_update_norm < 1e-10:\n",
    "            print(\"   ‚ùå fp_adapter is FROZEN (updates are zero)\")\n",
    "        elif total_update_norm > 0.01:\n",
    "            print(\"   ‚úÖ fp_adapter is TRAINABLE (updates are non-zero)\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  fp_adapter updates are very small\")\n",
    "        \n",
    "        # Check individual parameters\n",
    "        print(\"   Individual fp_adapter parameter updates:\")\n",
    "        for key in frozen_updates['fp_adapter']:\n",
    "            if isinstance(frozen_updates['fp_adapter'][key], dict):\n",
    "                for subkey in frozen_updates['fp_adapter'][key]:\n",
    "                    update_val = frozen_updates['fp_adapter'][key][subkey]\n",
    "                    norm = float(jnp.linalg.norm(jnp.ravel(update_val)))\n",
    "                    status = \"üßä FROZEN\" if norm < 1e-10 else \"üî• TRAINABLE\"\n",
    "                    print(f\"     {key}.{subkey}: norm={norm:.6f} {status}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "694b6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFYING ORIGINAL FROZEN ANALYSIS\n",
      "============================================================\n",
      "Recreating the exact test from the original frozen behavior analysis...\n",
      "‚úÖ Optimizer update successful\n",
      "\n",
      "High-level parameter group analysis:\n",
      "  classifier: total_grad=126.608932, total_update=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  cond_embeddings: total_grad=14.972701, total_update=0.000000, ratio=0.000000 üßä FROZEN\n",
      "  fp_adapter: total_grad=57.933586, total_update=0.000000, ratio=0.000000 üßä FROZEN\n",
      "    üîç fp_adapter detailed analysis:\n",
      "      Gradient magnitude: 57.933586\n",
      "      Update magnitude: 0.000000\n",
      "      Ratio (update/grad): 0.000000\n",
      "      Number of gradient leaves: 4\n",
      "      Number of update leaves: 4\n",
      "        Leaf 0: grad=0.640000, update=0.000000, ratio=0.000000\n",
      "        Leaf 1: grad=40.960011, update=0.000000, ratio=0.000000\n",
      "        Leaf 2: grad=0.640000, update=0.000000, ratio=0.000000\n",
      "        Leaf 3: grad=40.960011, update=0.000000, ratio=0.000000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify the original frozen behavior analysis\n",
    "print(\"üîç VERIFYING ORIGINAL FROZEN ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False) and new_train_state is not None:\n",
    "    # Recreate the exact test from the frozen behavior analysis\n",
    "    print(\"Recreating the exact test from the original frozen behavior analysis...\")\n",
    "    \n",
    "    # Create dummy gradients (same as original)\n",
    "    dummy_grads = jax.tree_util.tree_map(\n",
    "        lambda x: jnp.ones_like(x) * 0.01,  # Small gradient\n",
    "        new_train_state.params\n",
    "    )\n",
    "    \n",
    "    # Apply optimizer update (same as original)\n",
    "    try:\n",
    "        updates, new_opt_state = new_optimizer.update(\n",
    "            dummy_grads, \n",
    "            new_train_state.opt_state, \n",
    "            new_train_state.params\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Optimizer update successful\")\n",
    "        \n",
    "        # High-level parameter group analysis (same as original)\n",
    "        print(f\"\\nHigh-level parameter group analysis:\")\n",
    "        for param_group in ['classifier', 'cond_embeddings', 'fp_adapter']:\n",
    "            if param_group in dummy_grads and param_group in updates:\n",
    "                # Calculate total norms for each parameter group\n",
    "                grad_leaves = jax.tree_util.tree_leaves(dummy_grads[param_group])\n",
    "                update_leaves = jax.tree_util.tree_leaves(updates[param_group])\n",
    "                \n",
    "                total_grad_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in grad_leaves)))\n",
    "                total_update_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in update_leaves)))\n",
    "                ratio = total_update_norm / total_grad_norm if total_grad_norm > 0 else 0\n",
    "                \n",
    "                if total_update_norm < 1e-8:\n",
    "                    status = \"üßä FROZEN\"\n",
    "                elif ratio < 1e-4:\n",
    "                    status = \"üîí MOSTLY FROZEN\"\n",
    "                else:\n",
    "                    status = \"üî• ACTIVE\"\n",
    "                \n",
    "                print(f\"  {param_group}: total_grad={total_grad_norm:.6f}, total_update={total_update_norm:.6f}, ratio={ratio:.6f} {status}\")\n",
    "                \n",
    "                # Additional debugging for fp_adapter\n",
    "                if param_group == 'fp_adapter':\n",
    "                    print(f\"    üîç fp_adapter detailed analysis:\")\n",
    "                    print(f\"      Gradient magnitude: {total_grad_norm:.6f}\")\n",
    "                    print(f\"      Update magnitude: {total_update_norm:.6f}\")\n",
    "                    print(f\"      Ratio (update/grad): {ratio:.6f}\")\n",
    "                    print(f\"      Number of gradient leaves: {len(grad_leaves)}\")\n",
    "                    print(f\"      Number of update leaves: {len(update_leaves)}\")\n",
    "                    \n",
    "                    # Check individual leaves\n",
    "                    for i, (grad_leaf, update_leaf) in enumerate(zip(grad_leaves, update_leaves)):\n",
    "                        leaf_grad_norm = float(jnp.linalg.norm(jnp.ravel(grad_leaf)))\n",
    "                        leaf_update_norm = float(jnp.linalg.norm(jnp.ravel(update_leaf)))\n",
    "                        leaf_ratio = leaf_update_norm / leaf_grad_norm if leaf_grad_norm > 0 else 0\n",
    "                        print(f\"        Leaf {i}: grad={leaf_grad_norm:.6f}, update={leaf_update_norm:.6f}, ratio={leaf_ratio:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during optimizer update: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad7cc30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß OPTIMIZER CHAIN ORDER INVESTIGATION\n",
      "============================================================\n",
      "üß™ Testing different optimizer chain orders:\n",
      "\n",
      "1Ô∏è‚É£ Current order: clip -> adamw -> freeze\n",
      "2Ô∏è‚É£ Alternative order: freeze -> clip -> adamw\n",
      "\n",
      "  1Ô∏è‚É£ Testing Current optimizer:\n",
      "    ‚úÖ fp_adapter: TRAINABLE (update_norm=5.793282)\n",
      "    ‚úÖ classifier: FROZEN (update_norm=0.000000)\n",
      "    ‚ùå cond_embeddings: NOT FROZEN (update_norm=1.448497)\n",
      "\n",
      "  2Ô∏è‚É£ Testing Alternative optimizer:\n",
      "    ‚úÖ fp_adapter: TRAINABLE (update_norm=5.793282)\n",
      "    ‚ùå classifier: NOT FROZEN (update_norm=0.002546)\n",
      "    ‚ùå cond_embeddings: NOT FROZEN (update_norm=1.448497)\n",
      "\n",
      "3Ô∏è‚É£ Checking for mask inversion issue:\n",
      "Optax freeze documentation says:\n",
      "- mask=True means FROZEN (no updates)\n",
      "- mask=False means TRAINABLE (allow updates)\n",
      "\n",
      "Our mask values:\n",
      "  fp_adapter mask: {'fingerprint_adapter_dense': {'bias': False, 'kernel': False}, 'fingerprint_adapter_out': {'bias': False, 'kernel': False}}\n",
      "    fp_adapter.fingerprint_adapter_dense.bias: False (TRAINABLE)\n",
      "    fp_adapter.fingerprint_adapter_dense.kernel: False (TRAINABLE)\n",
      "    fp_adapter.fingerprint_adapter_out.bias: False (TRAINABLE)\n",
      "    fp_adapter.fingerprint_adapter_out.kernel: False (TRAINABLE)\n",
      "\n",
      "  classifier.Embed_0.embedding mask: True (should be True=FROZEN)\n",
      "  cond_embeddings.cond_dense_0.kernel mask: False (should be False=TRAINABLE)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test optimizer chain order issue\n",
    "print(\"üîß OPTIMIZER CHAIN ORDER INVESTIGATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False) and new_train_state is not None:\n",
    "    import optax\n",
    "    from flax import traverse_util\n",
    "    \n",
    "    # Recreate the freeze mask\n",
    "    def _should_freeze(path, v):\n",
    "        path_str = '.'.join(str(p.key) if hasattr(p, 'key') else str(p) for p in path)\n",
    "        return \"fp_adapter\" not in path_str\n",
    "    \n",
    "    mask = traverse_util.path_aware_map(_should_freeze, new_train_state.params)\n",
    "    mask[\"cond_embeddings\"][\"cond_dense_0\"][\"kernel\"] = False\n",
    "    mask[\"cond_embeddings\"][\"cond_dense_0\"][\"bias\"] = False\n",
    "    \n",
    "    print(\"üß™ Testing different optimizer chain orders:\")\n",
    "    \n",
    "    # Test 1: Current order (clip -> adamw -> freeze)\n",
    "    print(\"\\n1Ô∏è‚É£ Current order: clip -> adamw -> freeze\")\n",
    "    \n",
    "    optimizer_current = optax.chain(\n",
    "        optax.clip(1.0),  # Use a fixed clip value for testing\n",
    "        optax.adamw(0.001, b1=0.9, b2=0.999, weight_decay=0.01),\n",
    "        optax.transforms.freeze(mask),\n",
    "    )\n",
    "    \n",
    "    # Test 2: Alternative order (freeze -> clip -> adamw) \n",
    "    print(\"2Ô∏è‚É£ Alternative order: freeze -> clip -> adamw\")\n",
    "    \n",
    "    optimizer_alt = optax.chain(\n",
    "        optax.transforms.freeze(mask),\n",
    "        optax.clip(1.0),\n",
    "        optax.adamw(0.001, b1=0.9, b2=0.999, weight_decay=0.01),\n",
    "    )\n",
    "    \n",
    "    # Test both optimizers\n",
    "    dummy_params = new_train_state.params\n",
    "    dummy_grads = jax.tree_util.tree_map(lambda x: jnp.ones_like(x) * 0.01, dummy_params)\n",
    "    \n",
    "    for i, (name, optimizer) in enumerate([(\"Current\", optimizer_current), (\"Alternative\", optimizer_alt)], 1):\n",
    "        print(f\"\\n  {i}Ô∏è‚É£ Testing {name} optimizer:\")\n",
    "        \n",
    "        opt_state = optimizer.init(dummy_params)\n",
    "        updates, _ = optimizer.update(dummy_grads, opt_state, dummy_params)\n",
    "        \n",
    "        # Check fp_adapter updates\n",
    "        if 'fp_adapter' in updates:\n",
    "            fp_update_leaves = jax.tree_util.tree_leaves(updates['fp_adapter'])\n",
    "            total_update_norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in fp_update_leaves)))\n",
    "            \n",
    "            if total_update_norm < 1e-10:\n",
    "                print(f\"    ‚ùå fp_adapter: FROZEN (update_norm={total_update_norm:.6f})\")\n",
    "            else:\n",
    "                print(f\"    ‚úÖ fp_adapter: TRAINABLE (update_norm={total_update_norm:.6f})\")\n",
    "        \n",
    "        # Check other parameter groups\n",
    "        for param_group in ['classifier', 'cond_embeddings']:\n",
    "            if param_group in updates:\n",
    "                leaves = jax.tree_util.tree_leaves(updates[param_group])\n",
    "                norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in leaves)))\n",
    "                \n",
    "                if norm < 1e-10:\n",
    "                    print(f\"    ‚úÖ {param_group}: FROZEN (update_norm={norm:.6f})\")\n",
    "                else:\n",
    "                    print(f\"    ‚ùå {param_group}: NOT FROZEN (update_norm={norm:.6f})\")\n",
    "    \n",
    "    # Test 3: Check if there's a mask inversion issue\n",
    "    print(f\"\\n3Ô∏è‚É£ Checking for mask inversion issue:\")\n",
    "    print(\"Optax freeze documentation says:\")\n",
    "    print(\"- mask=True means FROZEN (no updates)\")\n",
    "    print(\"- mask=False means TRAINABLE (allow updates)\")\n",
    "    \n",
    "    print(f\"\\nOur mask values:\")\n",
    "    print(f\"  fp_adapter mask: {mask.get('fp_adapter', 'NOT FOUND')}\")\n",
    "    if 'fp_adapter' in mask:\n",
    "        for key in mask['fp_adapter']:\n",
    "            if isinstance(mask['fp_adapter'][key], dict):\n",
    "                for subkey in mask['fp_adapter'][key]:\n",
    "                    val = mask['fp_adapter'][key][subkey]\n",
    "                    status = \"FROZEN\" if val else \"TRAINABLE\"\n",
    "                    print(f\"    fp_adapter.{key}.{subkey}: {val} ({status})\")\n",
    "    \n",
    "    print(f\"\\n  classifier.Embed_0.embedding mask: {mask['classifier']['Embed_0']['embedding']} (should be True=FROZEN)\")\n",
    "    print(f\"  cond_embeddings.cond_dense_0.kernel mask: {mask['cond_embeddings']['cond_dense_0']['kernel']} (should be False=TRAINABLE)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "002f84c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ACTUAL TRAIN STATE OPTIMIZER ANALYSIS\n",
      "============================================================\n",
      "Comparing test optimizers vs actual train state optimizer...\n",
      "\n",
      "üéØ Testing actual train state optimizer:\n",
      "‚úÖ Optimizer update successful\n",
      "  classifier: update_norm=0.000000 üßä FROZEN\n",
      "  cond_embeddings: update_norm=0.000000 üßä FROZEN\n",
      "  fp_adapter: update_norm=0.000000 üßä FROZEN\n",
      "\n",
      "üìã Configuration check:\n",
      "  frozen: True\n",
      "  clip: 0.0\n",
      "  learning_rate: 1e-05\n",
      "  b2: 0.999\n",
      "  weight_decay: 1e-06\n",
      "\n",
      "üîß Optimizer structure comparison:\n",
      "  Actual optimizer type: <class 'optax._src.base.GradientTransformationExtraArgs'>\n",
      "\n",
      "üß™ Recreation test:\n",
      "  Recreated optimizer: fp_adapter FROZEN (norm=0.000000)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare with actual train state optimizer\n",
    "print(\"üîç ACTUAL TRAIN STATE OPTIMIZER ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False) and new_train_state is not None:\n",
    "    print(\"Comparing test optimizers vs actual train state optimizer...\")\n",
    "    \n",
    "    # Test the actual optimizer from the train state\n",
    "    print(\"\\nüéØ Testing actual train state optimizer:\")\n",
    "    \n",
    "    dummy_grads = jax.tree_util.tree_map(lambda x: jnp.ones_like(x) * 0.01, new_train_state.params)\n",
    "    \n",
    "    try:\n",
    "        updates, _ = new_optimizer.update(\n",
    "            dummy_grads, \n",
    "            new_train_state.opt_state, \n",
    "            new_train_state.params\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Optimizer update successful\")\n",
    "        \n",
    "        # Check each parameter group\n",
    "        for param_group in ['classifier', 'cond_embeddings', 'fp_adapter']:\n",
    "            if param_group in updates:\n",
    "                leaves = jax.tree_util.tree_leaves(updates[param_group])\n",
    "                norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in leaves)))\n",
    "                \n",
    "                if norm < 1e-10:\n",
    "                    status = \"üßä FROZEN\"\n",
    "                elif norm < 1e-6:\n",
    "                    status = \"üîí MOSTLY FROZEN\"\n",
    "                else:\n",
    "                    status = \"üî• TRAINABLE\"\n",
    "                \n",
    "                print(f\"  {param_group}: update_norm={norm:.6f} {status}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with actual optimizer: {e}\")\n",
    "    \n",
    "    # Check the configuration used to create the train state\n",
    "    print(f\"\\nüìã Configuration check:\")\n",
    "    print(f\"  frozen: {new_config.get('frozen', False)}\")\n",
    "    print(f\"  clip: {new_config.get('clip', 'not set')}\")\n",
    "    print(f\"  learning_rate: {new_config.get('learning_rate', 'not set')}\")\n",
    "    print(f\"  b2: {new_config.get('b2', 'not set')}\")\n",
    "    print(f\"  weight_decay: {new_config.get('weight_decay', 'not set')}\")\n",
    "    \n",
    "    # Try to compare the optimizer structure\n",
    "    print(f\"\\nüîß Optimizer structure comparison:\")\n",
    "    print(f\"  Actual optimizer type: {type(new_optimizer)}\")\n",
    "    \n",
    "    # Test if we can recreate the exact same optimizer\n",
    "    from md4 import train\n",
    "    \n",
    "    print(f\"\\nüß™ Recreation test:\")\n",
    "    try:\n",
    "        # Use the same parameters as the create_frozen_train_state function\n",
    "        schedule_fn_test = functools.partial(\n",
    "            train.get_learning_rate,\n",
    "            base_learning_rate=new_config.learning_rate,\n",
    "            num_steps=1000000,\n",
    "            warmup_steps=new_config.warmup_steps,\n",
    "            schedule_type=new_config.learning_rate_schedule,\n",
    "        )\n",
    "        \n",
    "        # This should match what's in create_frozen_train_state exactly\n",
    "        test_rng = jax.random.PRNGKey(42)\n",
    "        _, test_optimizer, test_train_state, _ = train.create_frozen_train_state(\n",
    "            new_config,\n",
    "            test_rng,\n",
    "            input_shape=(4,) + (new_config.max_length,),  # Small batch size\n",
    "            schedule_fn=schedule_fn_test,\n",
    "        )\n",
    "        \n",
    "        # Test this recreated optimizer\n",
    "        test_updates, _ = test_optimizer.update(\n",
    "            dummy_grads, \n",
    "            test_train_state.opt_state, \n",
    "            test_train_state.params\n",
    "        )\n",
    "        \n",
    "        # Check fp_adapter in recreated optimizer\n",
    "        if 'fp_adapter' in test_updates:\n",
    "            leaves = jax.tree_util.tree_leaves(test_updates['fp_adapter'])\n",
    "            norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in leaves)))\n",
    "            \n",
    "            if norm < 1e-10:\n",
    "                print(f\"  Recreated optimizer: fp_adapter FROZEN (norm={norm:.6f})\")\n",
    "            else:\n",
    "                print(f\"  Recreated optimizer: fp_adapter TRAINABLE (norm={norm:.6f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error recreating optimizer: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92510b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêõ CLIP=0.0 BUG INVESTIGATION\n",
      "============================================================\n",
      "Configuration clip value: 0.0\n",
      "\n",
      "üß™ Testing different clip configurations:\n",
      "\n",
      "1Ô∏è‚É£ With clip=0.0 (using optax.identity()):\n",
      "2Ô∏è‚É£ Without any clipping at all:\n",
      "3Ô∏è‚É£ With actual clipping (clip=1.0):\n",
      "\n",
      "  Testing identity optimizer:\n",
      "    ‚úÖ fp_adapter: TRAINABLE (norm=0.057933)\n",
      "\n",
      "  Testing no_clip optimizer:\n",
      "    ‚úÖ fp_adapter: TRAINABLE (norm=0.057933)\n",
      "\n",
      "  Testing with_clip optimizer:\n",
      "    ‚úÖ fp_adapter: TRAINABLE (norm=0.057933)\n",
      "\n",
      "4Ô∏è‚É£ Testing freeze mask directly:\n",
      "  ‚úÖ Direct freezer: fp_adapter TRAINABLE (norm=57.933586)\n",
      "\n",
      "5Ô∏è‚É£ Detailed mask investigation:\n",
      "  Complete freeze mask:\n",
      "  classifier.CondEmbedding_0.Dense_0.bias: True (FROZEN)\n",
      "  classifier.CondEmbedding_0.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.CondEmbedding_0.dense0.bias: True (FROZEN)\n",
      "  classifier.CondEmbedding_0.dense0.kernel: True (FROZEN)\n",
      "  classifier.Embed_0.embedding: True (FROZEN)\n",
      "  classifier.Transformer_0.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.Dense_1.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.Dense_1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.Dense_2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_0.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_1.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_10.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_11.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_2.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_3.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_4.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_5.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_6.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_7.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_8.feed_forward.w3.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.Dense_0.bias: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.Dense_0.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wk.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wo.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wq.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.attention.wv.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.feed_forward.w1.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.feed_forward.w2.kernel: True (FROZEN)\n",
      "  classifier.Transformer_0.TransformerBlock_9.feed_forward.w3.kernel: True (FROZEN)\n",
      "  cond_embeddings.cond_dense_0.bias: False (TRAINABLE)\n",
      "  cond_embeddings.cond_dense_0.kernel: False (TRAINABLE)\n",
      "  cond_embeddings.cond_dense_1.bias: True (FROZEN)\n",
      "  cond_embeddings.cond_dense_1.kernel: True (FROZEN)\n",
      "  cond_embeddings.cond_dense_2.bias: True (FROZEN)\n",
      "  cond_embeddings.cond_dense_2.kernel: True (FROZEN)\n",
      "  cond_embeddings.cond_dense_out.bias: True (FROZEN)\n",
      "  cond_embeddings.cond_dense_out.kernel: True (FROZEN)\n",
      "  fp_adapter.fingerprint_adapter_dense.bias: False (TRAINABLE)\n",
      "  fp_adapter.fingerprint_adapter_dense.kernel: False (TRAINABLE)\n",
      "  fp_adapter.fingerprint_adapter_out.bias: False (TRAINABLE)\n",
      "  fp_adapter.fingerprint_adapter_out.kernel: False (TRAINABLE)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the clip=0.0 issue\n",
    "print(\"üêõ CLIP=0.0 BUG INVESTIGATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if new_config.get('frozen', False) and new_train_state is not None:\n",
    "    import optax\n",
    "    from flax import traverse_util\n",
    "    \n",
    "    # Recreate the exact freeze mask\n",
    "    def _should_freeze(path, v):\n",
    "        path_str = '.'.join(str(p.key) if hasattr(p, 'key') else str(p) for p in path)\n",
    "        return \"fp_adapter\" not in path_str\n",
    "    \n",
    "    mask = traverse_util.path_aware_map(_should_freeze, new_train_state.params)\n",
    "    mask[\"cond_embeddings\"][\"cond_dense_0\"][\"kernel\"] = False\n",
    "    mask[\"cond_embeddings\"][\"cond_dense_0\"][\"bias\"] = False\n",
    "    \n",
    "    freezer = optax.transforms.freeze(mask)\n",
    "    \n",
    "    # Test different clip configurations\n",
    "    clip_value = new_config.get('clip', 0.0)\n",
    "    print(f\"Configuration clip value: {clip_value}\")\n",
    "    \n",
    "    print(f\"\\nüß™ Testing different clip configurations:\")\n",
    "    \n",
    "    # Test 1: With clip=0.0 (identity)\n",
    "    print(f\"\\n1Ô∏è‚É£ With clip=0.0 (using optax.identity()):\")\n",
    "    optimizer_identity = optax.chain(\n",
    "        optax.identity(),\n",
    "        optax.adamw(1e-5, b1=0.9, b2=0.999, weight_decay=1e-6),\n",
    "        freezer,\n",
    "    )\n",
    "    \n",
    "    # Test 2: Without any clipping\n",
    "    print(f\"2Ô∏è‚É£ Without any clipping at all:\")\n",
    "    optimizer_no_clip = optax.chain(\n",
    "        optax.adamw(1e-5, b1=0.9, b2=0.999, weight_decay=1e-6),\n",
    "        freezer,\n",
    "    )\n",
    "    \n",
    "    # Test 3: With actual clipping (clip > 0)\n",
    "    print(f\"3Ô∏è‚É£ With actual clipping (clip=1.0):\")\n",
    "    optimizer_with_clip = optax.chain(\n",
    "        optax.clip(1.0),\n",
    "        optax.adamw(1e-5, b1=0.9, b2=0.999, weight_decay=1e-6),\n",
    "        freezer,\n",
    "    )\n",
    "    \n",
    "    # Test all three\n",
    "    dummy_params = new_train_state.params\n",
    "    dummy_grads = jax.tree_util.tree_map(lambda x: jnp.ones_like(x) * 0.01, dummy_params)\n",
    "    \n",
    "    for name, optimizer in [\n",
    "        (\"identity\", optimizer_identity),\n",
    "        (\"no_clip\", optimizer_no_clip), \n",
    "        (\"with_clip\", optimizer_with_clip)\n",
    "    ]:\n",
    "        print(f\"\\n  Testing {name} optimizer:\")\n",
    "        \n",
    "        try:\n",
    "            opt_state = optimizer.init(dummy_params)\n",
    "            updates, _ = optimizer.update(dummy_grads, opt_state, dummy_params)\n",
    "            \n",
    "            # Check fp_adapter\n",
    "            if 'fp_adapter' in updates:\n",
    "                leaves = jax.tree_util.tree_leaves(updates['fp_adapter'])\n",
    "                norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in leaves)))\n",
    "                \n",
    "                if norm < 1e-10:\n",
    "                    print(f\"    ‚ùå fp_adapter: FROZEN (norm={norm:.6f})\")\n",
    "                else:\n",
    "                    print(f\"    ‚úÖ fp_adapter: TRAINABLE (norm={norm:.6f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå Error: {e}\")\n",
    "    \n",
    "    # Test 4: Check if the issue is with the mask itself\n",
    "    print(f\"\\n4Ô∏è‚É£ Testing freeze mask directly:\")\n",
    "    \n",
    "    # Test freezer alone\n",
    "    freezer_state = freezer.init(dummy_params)\n",
    "    frozen_updates_direct, _ = freezer.update(dummy_grads, freezer_state, dummy_params)\n",
    "    \n",
    "    if 'fp_adapter' in frozen_updates_direct:\n",
    "        leaves = jax.tree_util.tree_leaves(frozen_updates_direct['fp_adapter'])\n",
    "        norm = float(jnp.sqrt(sum(jnp.sum(jnp.square(leaf)) for leaf in leaves)))\n",
    "        \n",
    "        if norm < 1e-10:\n",
    "            print(f\"  ‚ùå Direct freezer: fp_adapter FROZEN (norm={norm:.6f})\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Direct freezer: fp_adapter TRAINABLE (norm={norm:.6f})\")\n",
    "    \n",
    "    # Investigate the mask values more carefully\n",
    "    print(f\"\\n5Ô∏è‚É£ Detailed mask investigation:\")\n",
    "    \n",
    "    def print_detailed_mask(mask_tree, path=\"\"):\n",
    "        if isinstance(mask_tree, dict):\n",
    "            for key, value in mask_tree.items():\n",
    "                print_detailed_mask(value, f\"{path}.{key}\" if path else key)\n",
    "        else:\n",
    "            print(f\"  {path}: {mask_tree} ({'FROZEN' if mask_tree else 'TRAINABLE'})\")\n",
    "    \n",
    "    print(\"  Complete freeze mask:\")\n",
    "    print_detailed_mask(mask)\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate potential issues in train.py\n",
    "print(\"üêõ POTENTIAL ISSUES INVESTIGATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Analyzing the actual train.py implementation...\")\n",
    "\n",
    "# Check if the _should_freeze function is properly implemented\n",
    "print(\"\\n1Ô∏è‚É£ FREEZE FUNCTION ANALYSIS\")\n",
    "print(\"Checking the _should_freeze function implementation...\")\n",
    "\n",
    "# Let's look at what the function should do according to the source\n",
    "print(\"Expected behavior:\")\n",
    "print(\"- fp_adapter parameters: should be TRAINABLE (return False)\")\n",
    "print(\"- All other parameters: should be FROZEN (return True)\")\n",
    "print(\"- cond_embeddings.cond_dense_0: manually set to TRAINABLE\")\n",
    "\n",
    "# Simulate the freeze logic\n",
    "def simulate_should_freeze(path):\n",
    "    \"\"\"Simulate the _should_freeze function from train.py\"\"\"\n",
    "    if \"fp_adapter\" in path:\n",
    "        return False  # Trainable\n",
    "    return True  # Frozen\n",
    "\n",
    "# Test it on our parameter paths\n",
    "test_paths = [\n",
    "    \"classifier.Embed_0.embedding\",\n",
    "    \"classifier.Transformer_0.Dense_0.kernel\", \n",
    "    \"cond_embeddings.cond_dense_0.kernel\",\n",
    "    \"cond_embeddings.cond_dense_1.kernel\",\n",
    "    \"fp_adapter.fingerprint_adapter_dense.kernel\",\n",
    "    \"fp_adapter.fingerprint_adapter_out.bias\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting freeze logic:\")\n",
    "for path in test_paths:\n",
    "    should_freeze = simulate_should_freeze(path)\n",
    "    # Special case for cond_dense_0 (manually set to trainable)\n",
    "    if \"cond_embeddings\" in path and \"cond_dense_0\" in path:\n",
    "        should_freeze = False  # Manually overridden\n",
    "    \n",
    "    status = \"üßä FROZEN\" if should_freeze else \"üî• TRAINABLE\"\n",
    "    print(f\"  {path}: {status}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ POTENTIAL ISSUES IDENTIFIED\")\n",
    "\n",
    "issues_found = []\n",
    "\n",
    "# Check if the model has the expected parameter groups\n",
    "if new_train_state is not None:\n",
    "    param_keys = list(new_train_state.params.keys())\n",
    "    \n",
    "    if 'fp_adapter' not in param_keys:\n",
    "        issues_found.append(\"‚ùå fp_adapter not found in model parameters\")\n",
    "    else:\n",
    "        print(\"‚úÖ fp_adapter found in model parameters\")\n",
    "    \n",
    "    if 'cond_embeddings' not in param_keys:\n",
    "        issues_found.append(\"‚ùå cond_embeddings not found in model parameters\")\n",
    "    else:\n",
    "        print(\"‚úÖ cond_embeddings found in model parameters\")\n",
    "        \n",
    "        # Check for cond_dense_0\n",
    "        if ('cond_embeddings' in new_train_state.params and \n",
    "            'cond_dense_0' in new_train_state.params['cond_embeddings']):\n",
    "            print(\"‚úÖ cond_dense_0 found in cond_embeddings\")\n",
    "        else:\n",
    "            issues_found.append(\"‚ùå cond_dense_0 not found in cond_embeddings\")\n",
    "\n",
    "# Check for potential configuration issues\n",
    "print(\"\\n3Ô∏è‚É£ CONFIGURATION COMPATIBILITY\")\n",
    "\n",
    "if 'frozen' in new_config and new_config.frozen:\n",
    "    print(\"‚úÖ Model is configured for frozen training\")\n",
    "    \n",
    "    if 'fingerprint_dim' in new_config and new_config.fingerprint_dim > 0:\n",
    "        print(\"‚úÖ Fingerprint conditioning is enabled\")\n",
    "    else:\n",
    "        issues_found.append(\"‚ö†Ô∏è  Fingerprint conditioning may not be properly configured\")\n",
    "        \n",
    "    if 'partial_load' in new_config and new_config.partial_load:\n",
    "        print(\"‚úÖ Partial loading is enabled\")\n",
    "    else:\n",
    "        issues_found.append(\"‚ö†Ô∏è  Partial loading is not enabled in config\")\n",
    "else:\n",
    "    issues_found.append(\"‚ö†Ô∏è  Model is not configured for frozen training\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ SUMMARY OF FINDINGS\")\n",
    "\n",
    "if not issues_found:\n",
    "    print(\"‚úÖ No critical issues found in the configuration!\")\n",
    "    print(\"The partial loading and frozen training setup appears to be correct.\")\n",
    "else:\n",
    "    print(\"Issues that need attention:\")\n",
    "    for issue in issues_found:\n",
    "        print(f\"  {issue}\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ RECOMMENDATIONS FOR DEBUGGING\")\n",
    "print(\"If you're experiencing issues with partial loading or frozen training:\")\n",
    "print(\"1. Verify that old checkpoints contain compatible parameter structures\")\n",
    "print(\"2. Check that the fingerprint dimensions match between old and new models\")\n",
    "print(\"3. Ensure that the fp_adapter layers are present in the new model architecture\")\n",
    "print(\"4. Verify that only the intended parameters are being updated during training\")\n",
    "print(\"5. Monitor training loss to ensure that trainable parameters are learning\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "md4 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
