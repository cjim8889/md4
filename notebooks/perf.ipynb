{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de1b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoreload disabled for clean performance testing\n"
     ]
    }
   ],
   "source": [
    "# Disable autoreload during performance testing to avoid duplicate executions\n",
    "%load_ext autoreload\n",
    "%autoreload 0\n",
    "\n",
    "# Note: Autoreload is disabled to prevent interference with performance measurements\n",
    "print(\"Autoreload disabled for clean performance testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6538575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 14:49:44.787611: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753368584.804220  305969 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753368584.809473  305969 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753368584.822999  305969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753368584.823013  305969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753368584.823015  305969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753368584.823017  305969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/home/wuhao/md4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wuhao/md4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)]\n",
      "JAX default backend: tpu\n",
      "Number of TPU devices: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Configure JAX to use TPU\n",
    "os.environ['JAX_PLATFORMS'] = 'tpu'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import flax.linen as nn\n",
    "from ml_collections import config_dict\n",
    "\n",
    "# Add the md4 module to the path\n",
    "sys.path.append('/home/wuhao/md4')\n",
    "\n",
    "from md4.configs.md4 import molecular\n",
    "from md4.models import utils as model_utils\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"JAX default backend: {jax.default_backend()}\")\n",
    "print(f\"Number of TPU devices: {len(jax.devices())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b29c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model type: md4\n",
      "  Dataset: pubchem_large\n",
      "  Vocab size: 1024\n",
      "  Max length: 128\n",
      "  Feature dim: 64\n",
      "  Number of layers: 12\n",
      "  Number of heads: 12\n",
      "  Dropout rate: 0.02\n",
      "  Fingerprint dim: 2048\n",
      "  Timesteps: 1000\n",
      "  Batch size: 1024\n",
      "\n",
      "Model created: <class 'md4.models.diffusion.md4.MD4'>\n",
      "Model: MD4(\n",
      "    # attributes\n",
      "    data_shape = (128,)\n",
      "    cont_time = True\n",
      "    timesteps = 1000\n",
      "    feature_dim = 64\n",
      "    num_heads = 12\n",
      "    antithetic_time_sampling = True\n",
      "    n_layers = 12\n",
      "    n_dit_layers = 0\n",
      "    dit_num_heads = 12\n",
      "    dit_hidden_size = 768\n",
      "    ch_mult = (1,)\n",
      "    vocab_size = 1024\n",
      "    noise_schedule_type = 'cosine'\n",
      "    dropout_rate = 0.02\n",
      "    use_attn_dropout = True\n",
      "    mlp_type = 'swiglu'\n",
      "    depth_scaled_init = True\n",
      "    cond_type = 'adaln_zero'\n",
      "    outside_embed = True\n",
      "    time_features = 't'\n",
      "    classes = -1\n",
      "    sampler = 'ancestral'\n",
      "    sampling_grid = 'uniform'\n",
      "    topp = 0.98\n",
      "    model_sharding = False\n",
      "    fingerprint_dim = 2048\n",
      "    atom_type_size = 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the molecular configuration\n",
    "config = molecular.get_config()\n",
    "config.vocab_size = 1024\n",
    "config.feature_dim = 64\n",
    "config.num_heads = 12\n",
    "config.n_layers = 12\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model type: {config.model_type}\")\n",
    "print(f\"  Dataset: {config.dataset}\")\n",
    "print(f\"  Vocab size: {config.vocab_size}\")\n",
    "print(f\"  Max length: {config.max_length}\")\n",
    "print(f\"  Feature dim: {config.feature_dim}\")\n",
    "print(f\"  Number of layers: {config.n_layers}\")\n",
    "print(f\"  Number of heads: {config.num_heads}\")\n",
    "print(f\"  Dropout rate: {config.dropout_rate}\")\n",
    "print(f\"  Fingerprint dim: {config.fingerprint_dim}\")\n",
    "print(f\"  Timesteps: {config.timesteps}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "\n",
    "# Create the model\n",
    "model = model_utils.get_model(config)\n",
    "print(f\"\\nModel created: {type(model)}\")\n",
    "print(f\"Model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a727d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (8, 128)\n",
      "Conditioning fingerprint shape: (8, 2048)\n",
      "\n",
      "Initializing model parameters...\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "xq: (8, 12, 128, 64), xk: (8, 12, 128, 64), xv: (8, 12, 128, 64)\n",
      "scores: (8, 12, 128, 128)\n",
      "Model output keys: ['loss', 'loss_diff', 'loss_prior', 'loss_recon']\n",
      "Output loss: 8.798684120178223\n",
      "Number of parameters: 91,821,952\n",
      "Model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model with dummy data\n",
    "batch_size = 8  # Use smaller batch size for performance testing\n",
    "seq_length = config.max_length\n",
    "\n",
    "# Create dummy inputs\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, sample_rng, init_rng = jax.random.split(rng, 3)\n",
    "\n",
    "# Input shape for molecular data (SMILES tokens)\n",
    "dummy_input = jnp.ones((batch_size, seq_length), dtype=\"int32\")\n",
    "\n",
    "# Create conditioning (fingerprint)\n",
    "conditioning = {\n",
    "    \"fingerprint\": jnp.zeros((batch_size, config.fingerprint_dim), dtype=\"int32\"),\n",
    "}\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Conditioning fingerprint shape: {conditioning['fingerprint'].shape}\")\n",
    "\n",
    "# Initialize the model\n",
    "print(\"\\nInitializing model parameters...\")\n",
    "output, variables = model.init_with_output(\n",
    "    {\"sample\": sample_rng, \"params\": init_rng},\n",
    "    dummy_input,\n",
    "    cond=conditioning,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "params = variables[\"params\"]\n",
    "state = {k: v for k, v in variables.items() if k != \"params\"}\n",
    "\n",
    "print(f\"Model output keys: {list(output.keys())}\")\n",
    "print(f\"Output loss: {output.get('loss', 'N/A')}\")\n",
    "print(f\"Number of parameters: {sum(x.size for x in jax.tree_util.tree_leaves(params)):,}\")\n",
    "print(\"Model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90a9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter overview:\n",
      "+---------------------------------------------------------------------+--------------+---------+-----------+-----------+---------+\n",
      "| Name                                                                | Shape        | Dtype   | Size      | Mean      | Std     |\n",
      "+---------------------------------------------------------------------+--------------+---------+-----------+-----------+---------+\n",
      "| classifier/CondEmbedding_0/Dense_0/bias                             | (64,)        | float32 | 64        | 0.0       | 0.0     |\n",
      "| classifier/CondEmbedding_0/Dense_0/kernel                           | (256, 64)    | float32 | 16,384    | -0.000179 | 0.0625  |\n",
      "| classifier/CondEmbedding_0/dense0/bias                              | (256,)       | float32 | 256       | 0.0       | 0.0     |\n",
      "| classifier/CondEmbedding_0/dense0/kernel                            | (128, 256)   | float32 | 32,768    | 0.000325  | 0.0882  |\n",
      "| classifier/Embed_0/embedding                                        | (1025, 64)   | float32 | 65,600    | -0.00036  | 0.125   |\n",
      "| classifier/Transformer_0/Dense_0/bias                               | (768,)       | float32 | 768       | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/Dense_0/kernel                             | (64, 768)    | float32 | 49,152    | -0.000422 | 0.125   |\n",
      "| classifier/Transformer_0/Dense_1/bias                               | (1536,)      | float32 | 1,536     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/Dense_1/kernel                             | (64, 1536)   | float32 | 98,304    | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/Dense_2/kernel                             | (768, 1024)  | float32 | 786,432   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_0/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_0/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | -5.2e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | 2.18e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | 8.12e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | -1.72e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | 2.14e-05  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 1.52e-05  | 0.00903 |\n",
      "| classifier/Transformer_0/TransformerBlock_0/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | 1.26e-05  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_1/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | -5.62e-06 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | 7.39e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | 2.1e-05   | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | 3.23e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | 1.92e-05  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 9.68e-06  | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_1/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | 6.96e-06  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/Dense_0/bias           | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_10/Dense_0/kernel         | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wk/kernel    | (768, 768)   | float32 | 589,824   | -0.000153 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wo/kernel    | (768, 768)   | float32 | 589,824   | 3.13e-06  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wq/kernel    | (768, 768)   | float32 | 589,824   | -0.000122 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/attention/wv/kernel    | (768, 768)   | float32 | 589,824   | 1.83e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w1/kernel | (768, 2048)  | float32 | 1,572,864 | -2.34e-05 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w2/kernel | (2048, 768)  | float32 | 1,572,864 | -2.8e-06  | 0.00903 |\n",
      "| classifier/Transformer_0/TransformerBlock_10/feed_forward/w3/kernel | (768, 2048)  | float32 | 1,572,864 | 4.35e-06  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/Dense_0/bias           | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_11/Dense_0/kernel         | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wk/kernel    | (768, 768)   | float32 | 589,824   | -2.25e-05 | 0.036   |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wo/kernel    | (768, 768)   | float32 | 589,824   | 1.9e-05   | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wq/kernel    | (768, 768)   | float32 | 589,824   | -2.55e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/attention/wv/kernel    | (768, 768)   | float32 | 589,824   | -5.46e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w1/kernel | (768, 2048)  | float32 | 1,572,864 | 5.53e-06  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w2/kernel | (2048, 768)  | float32 | 1,572,864 | -1.6e-06  | 0.00903 |\n",
      "| classifier/Transformer_0/TransformerBlock_11/feed_forward/w3/kernel | (768, 2048)  | float32 | 1,572,864 | 2.2e-06   | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_2/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | -2.35e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | 2.44e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | -1.46e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | -3.68e-05 | 0.036   |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | 6.37e-07  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | -1.77e-06 | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_2/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | -1.35e-05 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_3/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | 6.81e-06  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | -3.7e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | -2.58e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | -2.75e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | 5.95e-06  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | -2.06e-06 | 0.00901 |\n",
      "| classifier/Transformer_0/TransformerBlock_3/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | -2.17e-07 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_4/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | -2.63e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | 6.33e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | 0.000146  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | 4.65e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | -3.63e-06 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 8.16e-06  | 0.00901 |\n",
      "| classifier/Transformer_0/TransformerBlock_4/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | -2.85e-05 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_5/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | 3.05e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | -5.47e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | 2.89e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | 1.66e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | 2.1e-05   | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 6.9e-06   | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_5/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | 1.25e-05  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_6/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | 9.25e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | 7.67e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | -1.07e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | 6.24e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | -6.72e-06 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | -8.32e-06 | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_6/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | 1.08e-05  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_7/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | -4.53e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | -8.77e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | 2.39e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | -1.95e-06 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | -4.17e-06 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 3.49e-06  | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_7/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | 1.63e-07  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_8/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | 6.01e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | -1.82e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | -4.14e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | -8.89e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | 5.21e-06  | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 5.9e-06   | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_8/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | -5.48e-06 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/Dense_0/bias            | (4608,)      | float32 | 4,608     | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_9/Dense_0/kernel          | (64, 4608)   | float32 | 294,912   | 0.0       | 0.0     |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wk/kernel     | (768, 768)   | float32 | 589,824   | -4.36e-05 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wo/kernel     | (768, 768)   | float32 | 589,824   | -4.95e-06 | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wq/kernel     | (768, 768)   | float32 | 589,824   | 4.68e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/attention/wv/kernel     | (768, 768)   | float32 | 589,824   | 5.31e-05  | 0.0361  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w1/kernel  | (768, 2048)  | float32 | 1,572,864 | -4.36e-06 | 0.0147  |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w2/kernel  | (2048, 768)  | float32 | 1,572,864 | 1.13e-06  | 0.00902 |\n",
      "| classifier/Transformer_0/TransformerBlock_9/feed_forward/w3/kernel  | (768, 2048)  | float32 | 1,572,864 | -8.38e-06 | 0.0147  |\n",
      "| cond_embeddings/cond_dense_0/bias                                   | (1024,)      | float32 | 1,024     | 0.0       | 0.0     |\n",
      "| cond_embeddings/cond_dense_0/kernel                                 | (2048, 1024) | float32 | 2,097,152 | -8.09e-06 | 0.0221  |\n",
      "| cond_embeddings/cond_dense_1/bias                                   | (128,)       | float32 | 128       | 0.0       | 0.0     |\n",
      "| cond_embeddings/cond_dense_1/kernel                                 | (1024, 128)  | float32 | 131,072   | 0.000146  | 0.0312  |\n",
      "| cond_embeddings/cond_dense_2/bias                                   | (64,)        | float32 | 64        | 0.0       | 0.0     |\n",
      "| cond_embeddings/cond_dense_2/kernel                                 | (128, 64)    | float32 | 8,192     | -0.00154  | 0.0887  |\n",
      "| cond_embeddings/cond_dense_out/bias                                 | (64,)        | float32 | 64        | 0.0       | 0.0     |\n",
      "| cond_embeddings/cond_dense_out/kernel                               | (64, 64)     | float32 | 4,096     | -0.00223  | 0.126   |\n",
      "+---------------------------------------------------------------------+--------------+---------+-----------+-----------+---------+\n",
      "Total: 91,821,952 -- 367,287,808 bytes\n"
     ]
    }
   ],
   "source": [
    "from clu import parameter_overview\n",
    "print(\"\\nParameter overview:\")\n",
    "overview = parameter_overview.get_parameter_overview(params)\n",
    "print(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2efda242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PERFORMANCE TESTING - ACTUAL TRAIN STEP\n",
      "============================================================\n",
      "Created TrainState with step: 0\n",
      "Optimizer state initialized: True\n",
      "Metrics class keys: ['learning_rate', 'loss', 'loss_diff', 'loss_prior', 'loss_recon']\n",
      "\n",
      "Profiling actual train step performance:\n",
      "Sequence length: 128\n",
      "Number of profiling steps per batch size: 100\n",
      "------------------------------------------------------------\n",
      "\n",
      "Profiling batch size 256...\n",
      "  Warming up for batch size 256...\n",
      "  Capturing profiler trace to /home/wuhao/md4/profilenew/profile-data-bs-256...\n",
      "  Profiler trace saved to /home/wuhao/md4/profilenew/profile-data-bs-256\n",
      "  Final step: 100\n",
      "------------------------------------------------------------\n",
      "\n",
      "Profiler traces captured:\n",
      "  Batch size 256: /home/wuhao/md4/profilenew/profile-data-bs-256 (steps: 100)\n",
      "\n",
      "You can analyze these traces using TensorBoard:\n",
      "  tensorboard --logdir /home/wuhao/md4/profilenew/profile-data-bs-256\n",
      "\n",
      "Or open all traces in one TensorBoard session:\n",
      "  tensorboard --logdir /tmp --logdir_spec bs128:/tmp/profile-data-bs-128,bs256:/tmp/profile-data-bs-256,bs512:/tmp/profile-data-bs-512\n"
     ]
    }
   ],
   "source": [
    "# Performance testing - Train step timing using actual train.py functions\n",
    "print(\"=\" * 60)\n",
    "print(\"PERFORMANCE TESTING - ACTUAL TRAIN STEP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import optax\n",
    "import functools\n",
    "from md4.train import TrainState, get_learning_rate, create_metrics_class_from_keys, loss_fn\n",
    "\n",
    "# Create learning rate schedule function like in actual training\n",
    "num_train_steps = 10000  # Dummy value for schedule\n",
    "schedule_fn = functools.partial(\n",
    "    get_learning_rate,\n",
    "    base_learning_rate=config.learning_rate,\n",
    "    num_steps=num_train_steps,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    schedule_type=getattr(config, 'learning_rate_schedule', 'cosine'),\n",
    ")\n",
    "\n",
    "# Create optimizer exactly like in actual training\n",
    "optimizer = optax.chain(\n",
    "    optax.clip(config.clip) if config.clip > 0.0 else optax.identity(),\n",
    "    optax.adamw(\n",
    "        schedule_fn,\n",
    "        b1=0.9,\n",
    "        b2=config.b2,\n",
    "        weight_decay=config.weight_decay,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create TrainState exactly like in actual training\n",
    "train_state = TrainState(\n",
    "    step=0,\n",
    "    rng=jax.random.PRNGKey(42),\n",
    "    params=params,\n",
    "    ema_params=copy.deepcopy(params) if getattr(config, 'ema_rate', 0.0) > 0.0 else None,\n",
    "    opt_state=optimizer.init(params),\n",
    "    state=state,\n",
    ")\n",
    "\n",
    "# Create metrics class like in actual training\n",
    "# Get output keys from a dummy forward pass\n",
    "dummy_output, _ = model.init_with_output(\n",
    "    {\"sample\": jax.random.PRNGKey(0), \"params\": jax.random.PRNGKey(1)},\n",
    "    dummy_input,\n",
    "    cond=conditioning,\n",
    "    train=False,\n",
    ")\n",
    "metric_keys = sorted(list(dummy_output.keys()) + [\"learning_rate\"])\n",
    "train_metrics_class = create_metrics_class_from_keys(metric_keys)\n",
    "\n",
    "print(f\"Created TrainState with step: {train_state.step}\")\n",
    "print(f\"Optimizer state initialized: {train_state.opt_state is not None}\")\n",
    "print(f\"Metrics class keys: {metric_keys}\")\n",
    "\n",
    "# Create a simplified train step function without pmap operations\n",
    "@jax.jit\n",
    "def train_step_fn(train_state, batch):\n",
    "    \"\"\"Simplified train step function without pmap for performance testing.\"\"\"\n",
    "    rng, new_rng = jax.random.split(train_state.rng)\n",
    "    # Remove the pmap-specific fold_in operation\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, (new_state, metrics_dict)), grads = grad_fn(\n",
    "        train_state.params, train_state.state, rng, model, batch, train=True\n",
    "    )\n",
    "    \n",
    "    # Apply optimizer updates (without pmean for gradients)\n",
    "    updates, new_opt_state = optimizer.update(\n",
    "        grads, train_state.opt_state, train_state.params\n",
    "    )\n",
    "    new_params = optax.apply_updates(train_state.params, updates)\n",
    "    \n",
    "    # Handle EMA if configured\n",
    "    ema_rate = getattr(config, 'ema_rate', 0.0)\n",
    "    if ema_rate > 0.0:\n",
    "        new_ema_params = jax.tree_util.tree_map(\n",
    "            lambda x, y: x + (1.0 - ema_rate) * (y - x),\n",
    "            train_state.ema_params,\n",
    "            new_params,\n",
    "        )\n",
    "    else:\n",
    "        new_ema_params = None\n",
    "        \n",
    "    new_train_state = train_state.replace(\n",
    "        step=train_state.step + 1,\n",
    "        rng=new_rng,\n",
    "        params=new_params,\n",
    "        ema_params=new_ema_params,\n",
    "        opt_state=new_opt_state,\n",
    "        state=new_state,\n",
    "    )\n",
    "\n",
    "    \n",
    "    return new_train_state\n",
    "\n",
    "# Performance testing with different batch sizes - PROFILING ONLY\n",
    "batch_sizes = [256]  # Test various batch sizes\n",
    "num_profile_steps = 100  # Number of steps to profile for each batch size\n",
    "\n",
    "print(f\"\\nProfiling actual train step performance:\")\n",
    "print(f\"Sequence length: {seq_length}\")\n",
    "print(f\"Number of profiling steps per batch size: {num_profile_steps}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "profile_results = []\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    print(f\"\\nProfiling batch size {bs}...\")\n",
    "    \n",
    "    # Create batch in the format expected by train.py\n",
    "    batch = {\n",
    "        \"smiles\": jnp.ones((bs, seq_length), dtype=\"int32\"),\n",
    "        \"fingerprint\": jnp.zeros((bs, config.fingerprint_dim), dtype=\"int32\"),\n",
    "    }\n",
    "    \n",
    "    # Reset train state for each batch size\n",
    "    test_train_state = TrainState(\n",
    "        step=0,\n",
    "        rng=jax.random.PRNGKey(42),\n",
    "        params=params,\n",
    "        ema_params=copy.deepcopy(params) if getattr(config, 'ema_rate', 0.0) > 0.0 else None,\n",
    "        opt_state=optimizer.init(params),\n",
    "        state=state,\n",
    "    )\n",
    "    \n",
    "    # Warm up for this batch size (important for JIT compilation)\n",
    "    print(f\"  Warming up for batch size {bs}...\")\n",
    "    for _ in range(3):\n",
    "        test_train_state = train_step_fn(\n",
    "            train_state=test_train_state, \n",
    "            batch=batch\n",
    "        )\n",
    "        # Block to ensure compilation is complete\n",
    "        jax.block_until_ready([test_train_state])\n",
    "    \n",
    "    # Reset train state after warmup for realistic profiling\n",
    "    test_train_state = TrainState(\n",
    "        step=0,\n",
    "        rng=jax.random.PRNGKey(42),\n",
    "        params=params,\n",
    "        ema_params=copy.deepcopy(params) if getattr(config, 'ema_rate', 0.0) > 0.0 else None,\n",
    "        opt_state=optimizer.init(params),\n",
    "        state=state,\n",
    "    )\n",
    "    \n",
    "    # Capture profiler trace for this batch size\n",
    "    profile_dir = f\"/home/wuhao/md4/profilenew/profile-data-bs-{bs}\"\n",
    "    print(f\"  Capturing profiler trace to {profile_dir}...\")\n",
    "    \n",
    "    with jax.profiler.trace(profile_dir):\n",
    "        # Run realistic training steps with profiling\n",
    "        for i in range(num_profile_steps):\n",
    "            new_train_state = train_step_fn(\n",
    "                train_state=test_train_state,\n",
    "                batch=batch\n",
    "            )\n",
    "            # Use updated state for next iteration (realistic training simulation)\n",
    "            test_train_state = new_train_state\n",
    "\n",
    "        jax.block_until_ready([test_train_state])\n",
    "    print(f\"  Profiler trace saved to {profile_dir}\")\n",
    "    print(f\"  Final step: {test_train_state.step}\")\n",
    "    \n",
    "    profile_results.append({\n",
    "        'batch_size': bs,\n",
    "        'profile_dir': profile_dir,\n",
    "        'final_step': test_train_state.step\n",
    "    })\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nProfiler traces captured:\")\n",
    "for result in profile_results:\n",
    "    print(f\"  Batch size {result['batch_size']}: {result['profile_dir']} (steps: {result['final_step']})\")\n",
    "\n",
    "print(\"\\nYou can analyze these traces using TensorBoard:\")\n",
    "for result in profile_results:\n",
    "    print(f\"  tensorboard --logdir {result['profile_dir']}\")\n",
    "\n",
    "print(\"\\nOr open all traces in one TensorBoard session:\")\n",
    "print(\"  tensorboard --logdir /tmp --logdir_spec bs128:/tmp/profile-data-bs-128,bs256:/tmp/profile-data-bs-256,bs512:/tmp/profile-data-bs-512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b256ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "Model: md4 with 12 layers, 12 heads\n",
      "Sequence length: 128, Vocab size: 1023\n",
      "Feature dimension: 64, Fingerprint dimension: 2048\n",
      "Total parameters: 91,821,120\n",
      "Device: TPU_0(process=0,(0,0,0,0))\n",
      "\n",
      "Optimal batch size: 128 (211032 tokens/sec)\n",
      "\n",
      "Scaling analysis:\n",
      "  128 -> 256: 0.48x efficiency (0.96x throughput for 2.0x batch size)\n",
      "\n",
      "Recommendations:\n",
      "- Consider using smaller batch sizes for better efficiency\n",
      "- For single inference: ~77.6ms per sample\n",
      "- For batch processing: use batch size 128 for 211032 tokens/sec\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Profile analysis summary\n",
    "print(\"\\nPROFILING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'profile_results' in locals() and profile_results:\n",
    "    print(f\"Model: {config.model_type} with {config.n_layers} layers, {config.num_heads} heads\")\n",
    "    print(f\"Sequence length: {seq_length}, Vocab size: {config.vocab_size}\")\n",
    "    print(f\"Feature dimension: {config.feature_dim}, Fingerprint dimension: {config.fingerprint_dim}\")\n",
    "    print(f\"Total parameters: {sum(x.size for x in jax.tree_util.tree_leaves(params)):,}\")\n",
    "    print(f\"Device: {jax.devices()[0]}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Profiling completed for the following configurations:\")\n",
    "    for result in profile_results:\n",
    "        print(f\"  Batch size {result['batch_size']:3d}: {result['final_step']} training steps profiled\")\n",
    "        print(f\"    Profile data: {result['profile_dir']}\")\n",
    "    \n",
    "    print(\"\\nProfile Analysis Instructions:\")\n",
    "    print(\"1. Open TensorBoard to analyze the traces:\")\n",
    "    for result in profile_results:\n",
    "        print(f\"   tensorboard --logdir {result['profile_dir']}  # For batch size {result['batch_size']}\")\n",
    "    \n",
    "    print(\"\\n2. Compare all batch sizes in one view:\")\n",
    "    logdir_specs = \",\".join([f\"bs{r['batch_size']}:{r['profile_dir']}\" for r in profile_results])\n",
    "    print(f\"   tensorboard --logdir_spec {logdir_specs}\")\n",
    "    \n",
    "    print(\"\\n3. Key metrics to analyze in TensorBoard:\")\n",
    "    print(\"   - Trace Viewer: Step-by-step execution timeline\")\n",
    "    print(\"   - Overview Page: Operation statistics and recommendations\")\n",
    "    print(\"   - Memory Profile: Memory usage patterns\")\n",
    "    print(\"   - Kernel Stats: GPU/TPU kernel execution times\")\n",
    "    \n",
    "    print(\"\\n4. What to look for:\")\n",
    "    print(\"   - Memory bandwidth utilization\")\n",
    "    print(\"   - Compute vs memory bound operations\")\n",
    "    print(\"   - Batch size scaling efficiency\")\n",
    "    print(\"   - Gradient computation vs parameter update ratios\")\n",
    "    \n",
    "    # Calculate theoretical metrics\n",
    "    total_tokens_per_batch = {r['batch_size']: r['batch_size'] * seq_length for r in profile_results}\n",
    "    print(f\"\\nBatch configurations:\")\n",
    "    for result in profile_results:\n",
    "        tokens = total_tokens_per_batch[result['batch_size']]\n",
    "        print(f\"  Batch size {result['batch_size']:3d}: {tokens:6,} tokens per step\")\n",
    "    \n",
    "    print(f\"\\nRealistic training simulation completed:\")\n",
    "    print(f\"- Each profile includes {num_profile_steps} actual training steps\")\n",
    "    print(f\"- State updates and optimizer steps are realistic\")\n",
    "    print(f\"- Gradients computed and parameters updated each step\")\n",
    "    \n",
    "else:\n",
    "    print(\"No profiling results available. Run the profiling cell first.\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5dde11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "md4 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
